{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from jaxl.constants import *\n",
    "from jaxl.models.utils import (\n",
    "    get_model,\n",
    "    load_config,\n",
    "    load_params,\n",
    "    get_wsrl_model,\n",
    "    iterate_params,\n",
    "    get_policy,\n",
    "    policy_output_dim,\n",
    "    get_residual_policy,\n",
    ")\n",
    "from jaxl.envs import get_environment\n",
    "from jaxl.envs.rollouts import EvaluationRollout\n",
    "from jaxl.utils import get_device, parse_dict\n",
    "\n",
    "get_device(\"gpu:0\")\n",
    "# get_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"/home/bryan/research/jaxl/logs/manipulator_learning\"\n",
    "\n",
    "ablation_name = \"stack\"\n",
    "learner_name = \"cross_q-sac-06-03-24_16_53_41-9dd96b95-aefd-44fd-8894-4854c9c08abf\"\n",
    "learner_name = \"bc-06-04-24_09_43_02-a09b01c4-e33d-4e88-9eda-d7d36a68cdb8\"\n",
    "# learner_name = \"bc-100k_steps-06-04-24_09_57_35-e8bd5a54-9148-41a9-ace8-f33c5cfbab9f\"\n",
    "# learner_name = \"bc-10k_steps-06-04-24_10_06_35-333b32a8-c019-4fed-9b8f-1ce59166bb2b\"\n",
    "# learner_name = \"warm_start_reinforce-06-04-24_13_28_32-b356a022-d53a-4b11-9726-ccfe4dca0777\"\n",
    "# learner_name = \"rlpd-sac-06-05-24_16_15_56-c5ad96da-4ac4-466b-a221-74cfea71bd19\"\n",
    "learner_name = (\n",
    "    \"residual-rlpd-sac-06-06-24_17_55_49-1e0d722f-7e5d-4310-95de-2480ad35ab72\"\n",
    ")\n",
    "\n",
    "learner_path = os.path.join(result_dir, ablation_name, learner_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, config = load_config(learner_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"env_type\": \"manipulator_learning\",\n",
    "    \"env_name\": \"PandaPlayInsertTrayXYZState\",\n",
    "    \"env_kwargs\": {\"main_task\": \"stack\", \"dense_reward\": False},\n",
    "}\n",
    "env = get_environment(parse_dict(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_absorbing_state = False\n",
    "if config.learner_config.task == CONST_RESIDUAL:\n",
    "    backbone_act_dim = policy_output_dim(env.act_dim, config.model_config.backbone)\n",
    "    residual_act_dim = policy_output_dim(env.act_dim, config.model_config.residual)\n",
    "\n",
    "    backbone_model = get_model(\n",
    "        env.observation_space.shape, env.act_dim, config.model_config.backbone\n",
    "    )\n",
    "    residual_model = get_model(\n",
    "        env.observation_space.shape, residual_act_dim, config.model_config.residual\n",
    "    )\n",
    "    policy = get_residual_policy(\n",
    "        backbone_model,\n",
    "        residual_model,\n",
    "        config.model_config,\n",
    "    )\n",
    "else:\n",
    "    model_out_dim = policy_output_dim(env.act_dim, config.learner_config)\n",
    "    if config.learner_config.learner == CONST_BC:\n",
    "        model = get_model(\n",
    "            int(np.prod(env.observation_space.shape)) + 1,\n",
    "            env.act_dim,\n",
    "            config.model_config,\n",
    "        )\n",
    "        include_absorbing_state = True\n",
    "    elif config.learner_config.task == CONST_WSRL:\n",
    "        model = get_wsrl_model(\n",
    "            env.observation_space.shape, model_out_dim, config.model_config.policy\n",
    "        )\n",
    "        include_absorbing_state = True\n",
    "    else:\n",
    "        model = get_model(\n",
    "            env.observation_space.shape, model_out_dim, config.model_config.policy\n",
    "        )\n",
    "    policy = get_policy(model, config.learner_config)\n",
    "\n",
    "params = load_params(f\"{learner_path}:400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 50\n",
    "eval_seed = 42\n",
    "render = False\n",
    "random = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = EvaluationRollout(env, eval_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout.rollout(\n",
    "    params[CONST_MODEL_DICT][CONST_MODEL][CONST_POLICY],\n",
    "    policy,\n",
    "    False,\n",
    "    total_episodes,\n",
    "    random=random,\n",
    "    render=render,\n",
    "    include_absorbing_state=include_absorbing_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rollout.episodic_returns), np.std(rollout.episodic_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10k: (203.98, 147.88853775732588)  \n",
    "100k: (253.7, 127.34115595517422)  \n",
    "1M: (215.96, 148.52123888521803)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Residual RLPD @ 300 deterministic: (208.96, 150.14752212407635)\n",
    "Residual RLPD @ 400 deterministic: (210.16, 137.68796025796883)\n",
    "Residual RLPD @ 400 stochastic: (213.56, 135.53481619126504)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pickle.load(gzip.open(\"/home/bryan/research/jaxl/test_1.pkl\", \"rb\"))\n",
    "data_2 = pickle.load(gzip.open(\"/home/bryan/research/jaxl/test_2.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(data_1[\"actions\"] != data_2[\"actions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(data_1[\"observations\"] != data_2[\"observations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
