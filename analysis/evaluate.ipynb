{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from jaxl.constants import *\n",
    "from jaxl.models.utils import (\n",
    "    get_model,\n",
    "    load_config,\n",
    "    load_params,\n",
    "    get_wsrl_model,\n",
    "    iterate_params,\n",
    "    get_policy,\n",
    "    policy_output_dim,\n",
    "    get_residual_policy,\n",
    ")\n",
    "from jaxl.envs import get_environment\n",
    "from jaxl.envs.rollouts import EvaluationRollout\n",
    "from jaxl.utils import get_device, parse_dict\n",
    "\n",
    "# get_device(\"gpu:0\")\n",
    "get_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"/home/bryan/research/jaxl/logs/manipulator_learning\"\n",
    "\n",
    "ablation_name = \"stack\"\n",
    "learner_name = \"cross_q-sac-06-03-24_16_53_41-9dd96b95-aefd-44fd-8894-4854c9c08abf\"\n",
    "learner_name = \"bc-06-04-24_09_43_02-a09b01c4-e33d-4e88-9eda-d7d36a68cdb8\"\n",
    "# learner_name = \"bc-100k_steps-06-04-24_09_57_35-e8bd5a54-9148-41a9-ace8-f33c5cfbab9f\"\n",
    "# learner_name = \"bc-10k_steps-06-04-24_10_06_35-333b32a8-c019-4fed-9b8f-1ce59166bb2b\"\n",
    "# learner_name = \"warm_start_reinforce-06-04-24_13_28_32-b356a022-d53a-4b11-9726-ccfe4dca0777\"\n",
    "# learner_name = \"rlpd-sac-06-05-24_16_15_56-c5ad96da-4ac4-466b-a221-74cfea71bd19\"\n",
    "# learner_name = (\n",
    "#     \"residual-rlpd-sac-06-06-24_17_55_49-1e0d722f-7e5d-4310-95de-2480ad35ab72\"\n",
    "# )\n",
    "# learner_name = \"residual-rlpd-sac-fixed_temp-06-07-24_09_25_20-c64a33d6-de4f-4cae-96e9-e4a09ef9b50c\"\n",
    "learner_name = \"residual-rlpd-cross_q-deterministic_exploration-wide_critic-06-10-24_11_12_20-c40f7bbb-80de-47a6-b02f-a3568dd1a877\"\n",
    "\n",
    "learner_path = os.path.join(result_dir, ablation_name, learner_name)\n",
    "\n",
    "checkpoint = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(logging_config=namespace(save_path='./logs/manipulator_learning/stack',\n",
       "                                   experiment_name='residual-rlpd-cross_q-deterministic_exploration-wide_critic',\n",
       "                                   log_interval=1,\n",
       "                                   checkpoint_interval=10),\n",
       "          model_config=namespace(backbone=namespace(architecture='mlp',\n",
       "                                                    layers=[256, 256, 256],\n",
       "                                                    activation='tanh',\n",
       "                                                    flatten=True,\n",
       "                                                    policy_distribution='deterministic',\n",
       "                                                    pretrained_model='/home/bryan/research/jaxl/logs/manipulator_learning/stack/bc-10k_steps-06-04-24_10_06_35-333b32a8-c019-4fed-9b8f-1ce59166bb2b:latest',\n",
       "                                                    include_absorbing_state=True),\n",
       "                                 residual=namespace(architecture='mlp',\n",
       "                                                    layers=[256, 256, 256],\n",
       "                                                    activation='tanh',\n",
       "                                                    flatten=True,\n",
       "                                                    std_transform='squareplus',\n",
       "                                                    policy_distribution='squashed_gaussian'),\n",
       "                                 qf=namespace(architecture='ensemble',\n",
       "                                              model=namespace(architecture='mlp',\n",
       "                                                              layers=[2048,\n",
       "                                                                      2048],\n",
       "                                                              flatten=True,\n",
       "                                                              use_batch_norm=True),\n",
       "                                              num_models=2,\n",
       "                                              vmap_all=False),\n",
       "                                 qf_encoding=namespace(q_function='state_action_input',\n",
       "                                                       type='concatenate_inputs_encoding',\n",
       "                                                       kwargs=namespace())),\n",
       "          optimizer_config=namespace(residual=namespace(optimizer='adam',\n",
       "                                                        lr=namespace(scheduler='constant_schedule',\n",
       "                                                                     scheduler_kwargs=namespace(value=0.0003)),\n",
       "                                                        max_grad_norm=False),\n",
       "                                     qf=namespace(optimizer='adam',\n",
       "                                                  lr=namespace(scheduler='constant_schedule',\n",
       "                                                               scheduler_kwargs=namespace(value=0.0003)),\n",
       "                                                  max_grad_norm=False),\n",
       "                                     temp=namespace(optimizer='adam',\n",
       "                                                    lr=namespace(scheduler='constant_schedule',\n",
       "                                                                 scheduler_kwargs=namespace(value=0.0003)),\n",
       "                                                    max_grad_norm=False)),\n",
       "          learner_config=namespace(task='residual',\n",
       "                                   env_config=namespace(env_type='manipulator_learning',\n",
       "                                                        env_name='PandaPlayInsertTrayXYZState',\n",
       "                                                        env_kwargs=namespace(main_task='stack',\n",
       "                                                                             dense_reward=False)),\n",
       "                                   seeds=namespace(model_seed=42,\n",
       "                                                   buffer_seed=42,\n",
       "                                                   demo_buffer_seed=43,\n",
       "                                                   env_seed=42,\n",
       "                                                   learner_seed=42),\n",
       "                                   buffer_config=namespace(buffer_type='default',\n",
       "                                                           buffer_size=1000000),\n",
       "                                   demo_buffer_config=namespace(load_buffer='/home/bryan/research/lfgp/lfgp_data/custom_expert_data/stack/1000000_steps_no_extra_final/int_0.gz',\n",
       "                                                                buffer_type='default',\n",
       "                                                                set_size=10000),\n",
       "                                   buffer_warmup=1000,\n",
       "                                   random_explore_action=False,\n",
       "                                   num_steps_per_epoch=5000,\n",
       "                                   batch_size=256,\n",
       "                                   learner='sac',\n",
       "                                   variant='rlpd:cross_q',\n",
       "                                   remove_demo_absorbing_state=True,\n",
       "                                   obs_rms=False,\n",
       "                                   value_rms=False,\n",
       "                                   gamma=0.99,\n",
       "                                   update_frequency=1,\n",
       "                                   target_entropy='auto',\n",
       "                                   initial_temperature=0.2,\n",
       "                                   qf_loss_setting=namespace(coefficient=1.0,\n",
       "                                                             reduction='mean',\n",
       "                                                             include_entropy_regularization=False),\n",
       "                                   pi_loss_setting=namespace(coefficient=1.0,\n",
       "                                                             reduction='mean'),\n",
       "                                   temp_loss_setting=namespace(coefficient=1.0,\n",
       "                                                               reduction='mean'),\n",
       "                                   num_qf_updates=1,\n",
       "                                   actor_update_frequency=20,\n",
       "                                   target_update_frequency=1,\n",
       "                                   tau=0.005),\n",
       "          train_config=namespace(num_epochs=1000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, config = load_config(learner_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded EGL 1.5 after reload.\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=Quadro RTX 5000 with Max-Q Design/PCIe/SSE2\n",
      "GL_VERSION=3.3.0 NVIDIA 535.171.04\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30 NVIDIA via Cg compiler\n",
      "Version = 3.3.0 NVIDIA 535.171.04\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = Quadro RTX 5000 with Max-Q Design/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EGL device choice: -1 of 4.\n"
     ]
    }
   ],
   "source": [
    "env_config = {\n",
    "    \"env_type\": \"manipulator_learning\",\n",
    "    \"env_name\": \"PandaPlayInsertTrayXYZState\",\n",
    "    \"env_kwargs\": {\"main_task\": \"stack\", \"dense_reward\": False},\n",
    "}\n",
    "env = get_environment(parse_dict(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: jaxlib/cuda/versions_helpers.cc:99: operation cuInit(0) failed: CUDA_ERROR_NO_DEVICE.(Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "include_absorbing_state = False\n",
    "if config.learner_config.task == CONST_RESIDUAL:\n",
    "    backbone_act_dim = policy_output_dim(env.act_dim, config.model_config.backbone)\n",
    "    residual_act_dim = policy_output_dim(env.act_dim, config.model_config.residual)\n",
    "\n",
    "    backbone_model = get_model(\n",
    "        env.observation_space.shape, env.act_dim, config.model_config.backbone\n",
    "    )\n",
    "    residual_model = get_model(\n",
    "        env.observation_space.shape, residual_act_dim, config.model_config.residual\n",
    "    )\n",
    "    policy = get_residual_policy(\n",
    "        backbone_model,\n",
    "        residual_model,\n",
    "        config.model_config,\n",
    "    )\n",
    "else:\n",
    "    model_out_dim = policy_output_dim(env.act_dim, config.learner_config)\n",
    "    if config.learner_config.learner == CONST_BC:\n",
    "        model = get_model(\n",
    "            int(np.prod(env.observation_space.shape)) + 1,\n",
    "            env.act_dim,\n",
    "            config.model_config,\n",
    "        )\n",
    "        include_absorbing_state = True\n",
    "    elif config.learner_config.task == CONST_WSRL:\n",
    "        model = get_wsrl_model(\n",
    "            env.observation_space.shape, model_out_dim, config.model_config.policy\n",
    "        )\n",
    "        include_absorbing_state = True\n",
    "    else:\n",
    "        model = get_model(\n",
    "            env.observation_space.shape, model_out_dim, config.model_config.policy\n",
    "        )\n",
    "    policy = get_policy(model, config.learner_config)\n",
    "\n",
    "params = load_params(f\"{learner_path}:{checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 50\n",
    "eval_seed = 42\n",
    "render = False\n",
    "random = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = EvaluationRollout(env, eval_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:54<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "rollout.rollout(\n",
    "    params[CONST_MODEL_DICT][CONST_MODEL][CONST_POLICY],\n",
    "    policy,\n",
    "    False,\n",
    "    total_episodes,\n",
    "    random=random,\n",
    "    render=render,\n",
    "    include_absorbing_state=include_absorbing_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281.26, 97.1332713337711, 45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rollout.episodic_returns), np.std(rollout.episodic_returns), np.sum(\n",
    "    np.array(rollout.episodic_returns) > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10k: (203.98, 147.88853775732588)  \n",
    "100k: (253.7, 127.34115595517422)  \n",
    "1M: (215.96, 148.52123888521803)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Residual RLPD @ 300 deterministic: (208.96, 150.14752212407635)\n",
    "Residual RLPD @ 400 deterministic: (210.16, 137.68796025796883)\n",
    "Residual RLPD @ 400 stochastic: (213.56, 135.53481619126504)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Residual RLPD with fixed temp @ initialization random: (130.32, 139.2440217747247)\n",
    "Residual RLPD with fixed temp @ 10 random: (125.94, 150.11827470364827)\n",
    "Residual RLPD with fixed temp @ 20 random: (224.86, 137.30244134755944)\n",
    "Residual RLPD with fixed temp @ 150 random: (252.2, 125.54106897744657)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Residual RLPD CrossQ @ 160 deterministic: (280.46, 94.8232482042247, 46)\n",
    "Residual RLPD CrossQ @ latest deterministic: (281.26, 97.1332713337711, 45)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
