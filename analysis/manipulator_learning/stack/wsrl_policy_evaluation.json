{
    "logging_config": {
        "save_path": "./logs/manipulator_learning/stack",
        "experiment_name": "warm_start_policy_evaluation",
        "log_interval": 10,
        "checkpoint_interval": 100
    },
    "model_config": {
        "policy": {
            "architecture": "mlp",
            "layers": [
                256,
                256,
                256
            ],
            "activation": "tanh",
            "flatten": true
        },
        "vf": {
            "architecture": "mlp",
            "layers": [256, 256, 256],
            "flatten": true
        }
    },
    "optimizer_config": {
        "vf": {
            "optimizer": "adam",
            "lr": {
                "scheduler": "constant_schedule",
                "scheduler_kwargs": {
                    "value": 3e-4
                }
            },
            "max_grad_norm": false
        }
    },
    "learner_config": {
        "task": "warm_start_reinforcement_learning",
        "env_config": {
            "env_type": "manipulator_learning",
            "env_name": "PandaPlayInsertTrayXYZState",
            "env_kwargs": {
                "main_task": "stack",
                "dense_reward": false
            },
            "include_absorbing_state": true
        },
        "seeds": {
            "model_seed": 42,
            "buffer_seed": 42,
            "env_seed": 42
        },
        "buffer_config": {
            "buffer_type": "default",
            "buffer_size": 3600
        },
        "num_steps_per_epoch": 3600,
        "learner": "policy_evaluation",
        "gamma": 0.99,
        "eps": 1e-05,
        "obs_rms": false,
        "value_rms": false,
        "policy_distribution": "deterministic",
        "min_std": 1e-06,
        "vf_loss_setting": {
            "coefficient": 1.0,
            "reduction": "mean"
        },
        "load_pretrain": {
            "checkpoint_path": "/home/bryan/research/jaxl/logs/manipulator_learning/stack/bc-10k_steps-06-04-24_10_06_35-333b32a8-c019-4fed-9b8f-1ce59166bb2b:latest",
            "load_components": ["policy"]
        }
    },
    "train_config": {
        "num_epochs": 1000
    }
}
