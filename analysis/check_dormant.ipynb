{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "from penzai import pz\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from jaxl.constants import *\n",
    "from jaxl.models.utils import get_model, load_config, load_params, get_wsrl_model, iterate_params, get_policy, policy_output_dim\n",
    "from jaxl.buffers import get_buffer\n",
    "from jaxl.utils import get_device, parse_dict\n",
    "\n",
    "import IPython\n",
    "\n",
    "pz.ts.register_as_default()\n",
    "\n",
    "# Optional automatic array visualization extras:\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()\n",
    "pz.ts.active_autovisualizer.set_interactive(pz.ts.ArrayAutovisualizer())\n",
    "\n",
    "get_device(\"gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"/home/bryan/research/jaxl/logs/manipulator_learning\"\n",
    "\n",
    "ablation_name = \"stack\"\n",
    "# learner_name = \"bc-10k_steps-06-04-24_10_06_35-333b32a8-c019-4fed-9b8f-1ce59166bb2b\"\n",
    "# learner_name = \"warm_start_policy_evaluation-06-05-24_10_50_37-f9950c16-2b62-4078-85fd-2e43f5e6d1ed\"\n",
    "# learner_name = \"rlpd-sac-06-05-24_16_15_56-c5ad96da-4ac4-466b-a221-74cfea71bd19\"\n",
    "learner_name = \"rlpd-sac-high_utd-06-06-24_08_51_26-65753ce9-cb20-4d8b-ad9f-8b9c24b98b14\"\n",
    "\n",
    "learner_path = os.path.join(result_dir, ablation_name, learner_name)\n",
    "check_policy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, config = load_config(learner_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Buffer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_config = parse_dict(dict(\n",
    "    load_buffer='/home/bryan/research/lfgp/lfgp_data/custom_expert_data/stack/1000000_steps_no_extra_final/int_0.gz',\n",
    "    buffer_type='default',\n",
    "    set_size=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = get_buffer(buffer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out_dim = policy_output_dim(buffer.act_dim, config.learner_config)\n",
    "\n",
    "param_key = CONST_POLICY\n",
    "if config.learner_config.learner == CONST_BC:\n",
    "    model = get_model(\n",
    "        int(np.prod(buffer.input_dim)),\n",
    "        buffer.act_dim,\n",
    "        config.model_config\n",
    "    )\n",
    "    include_absorbing_state = True\n",
    "elif config.learner_config.task == CONST_WSRL:\n",
    "    if config.learner_config.learner == CONST_POLICY_EVALUATION:\n",
    "        model = get_model(\n",
    "            int(np.prod(buffer.input_dim)),\n",
    "            (1,),\n",
    "            config.model_config.vf\n",
    "        )\n",
    "        include_absorbing_state = True\n",
    "        param_key = CONST_VF\n",
    "    else:\n",
    "        model = get_wsrl_model(\n",
    "            int(np.prod(buffer.input_dim)),\n",
    "            model_out_dim,\n",
    "            config.model_config.policy\n",
    "        )\n",
    "        include_absorbing_state = True\n",
    "else:\n",
    "    if check_policy:\n",
    "        model = get_model(\n",
    "            int(np.prod(buffer.input_dim)) - 1,\n",
    "            model_out_dim,\n",
    "            config.model_config.policy\n",
    "        )\n",
    "    else:\n",
    "        param_key = CONST_VF if hasattr(config.model_config, CONST_VF) else CONST_QF\n",
    "        if param_key == CONST_QF:\n",
    "            model = get_model(\n",
    "                int(np.prod(buffer.input_dim)) - 1 + int(np.prod(buffer.act_dim)),\n",
    "                (1,),\n",
    "                config.model_config.qf\n",
    "            )\n",
    "        else:\n",
    "            model = get_model(\n",
    "                int(np.prod(buffer.input_dim)) - 1,\n",
    "                (1,),\n",
    "                config.model_config.vf\n",
    "            )\n",
    "    include_absorbing_state = False\n",
    "\n",
    "obss, _, acts = buffer.sample(256)[:3]\n",
    "\n",
    "if not include_absorbing_state:\n",
    "    obss = obss[..., :-1]\n",
    "\n",
    "print(obss.shape, acts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dormant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_outputs(params, obss, acts, config, model, param_key):\n",
    "    multi_output = False\n",
    "    if param_key == CONST_QF:\n",
    "        if config.model_config.qf.architecture == CONST_ENSEMBLE:\n",
    "            out, state = jax.vmap(\n",
    "                partial(\n",
    "                    model.model.model.apply,\n",
    "                    capture_intermediates=True,\n",
    "                    mutable=[\"intermediates\"],\n",
    "                    eval=True\n",
    "                ),\n",
    "                in_axes=[0, None]\n",
    "            )(\n",
    "                params[CONST_MODEL_DICT][CONST_MODEL][param_key],\n",
    "                np.concatenate((obss, acts[:, None]), axis=-1),\n",
    "            )\n",
    "            multi_output = True\n",
    "        else:\n",
    "            out, state = model.model.model.apply(\n",
    "                params[CONST_MODEL_DICT][CONST_MODEL][param_key],\n",
    "                np.concatenate((obss, acts[:, None]), axis=-1),\n",
    "                capture_intermediates=True,\n",
    "                mutable=[\"intermediates\"],\n",
    "                eval=True\n",
    "            )\n",
    "    else:\n",
    "        out, state = model.model.apply(\n",
    "            params[CONST_MODEL_DICT][CONST_MODEL][param_key],\n",
    "            obss,\n",
    "            capture_intermediates=True,\n",
    "            mutable=[\"intermediates\"],\n",
    "            eval=True\n",
    "        )\n",
    "    return out, state, multi_output\n",
    "\n",
    "inference = partial(\n",
    "    get_model_outputs,\n",
    "    config=config,\n",
    "    model=model,\n",
    "    param_key=param_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_params(f\"{learner_path}:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dormant(params, obss, acts, dormant_threshold=0.025):\n",
    "    out, state, multi_output = inference(params, obss, acts)\n",
    "    dormant_score = dict()\n",
    "    is_dormant = dict()\n",
    "    for (kp, val) in jax.tree_util.tree_flatten_with_path(state[\"intermediates\"])[0]:\n",
    "        if getattr(kp[0], \"key\", False) == \"__call__\":\n",
    "            continue\n",
    "        per_neuron_score = jnp.mean(jnp.abs(val), axis=1 if multi_output else 0)\n",
    "        curr_key = \"/\".join([curr_kp.key if hasattr(curr_kp, \"key\") else str(curr_kp.idx) for curr_kp in kp][:-2])\n",
    "        # XXX: https://github.com/google/dopamine/issues/209\n",
    "        dormant_score[curr_key] = (per_neuron_score / jnp.mean(per_neuron_score, axis=-1, keepdims=True))\n",
    "        is_dormant[curr_key] = dormant_score[curr_key] <= dormant_threshold\n",
    "\n",
    "        if np.prod(dormant_score[curr_key].shape) % 4 == 0:\n",
    "            if multi_output:\n",
    "                dormant_score[curr_key] = dormant_score[curr_key].reshape((len(dormant_score[curr_key]), 4, -1))\n",
    "            else:\n",
    "                dormant_score[curr_key] = dormant_score[curr_key].reshape((4, -1))\n",
    "    return dormant_score, is_dormant, multi_output\n",
    "\n",
    "def compute_dormant_percentage(is_dormant, multi_output):\n",
    "    return jax.tree_util.tree_reduce(\n",
    "        lambda x, y: x + jnp.sum(y, axis=-1),\n",
    "        is_dormant,\n",
    "        0\n",
    "    ) / jax.tree_util.tree_reduce(\n",
    "        lambda x, y: x + np.prod(y.shape[int(multi_output):]),\n",
    "        is_dormant,\n",
    "        0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dormant_score, is_dormant, multi_output = compute_dormant(params, obss, acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([(dormant_score[key]).flatten() for key in list(dormant_score.keys())[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dormant_percentage(is_dormant, multi_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"/\".join([curr_kp.key for curr_kp in kp]): pz.nx.wrap(val) for (kp, val) in jax.tree_util.tree_flatten_with_path(params[\"model_dict\"][\"model\"][param_key])[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Dormant Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_iter = iterate_params(f\"{learner_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dormant_threshold = 0.25\n",
    "for params, checkpoint_i in params_iter:\n",
    "    dormant_score, is_dormant, multi_output = compute_dormant(params, obss, acts, dormant_threshold)\n",
    "    print(checkpoint_i, compute_dormant_percentage(is_dormant, multi_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
