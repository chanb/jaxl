{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as torch_datasets\n",
    "import torchvision.transforms as torch_transforms\n",
    "\n",
    "from jaxl.datasets.omniglot import MultitaskOmniglotBursty, MultitaskOmniglotNWayKShot, MultitaskOmniglotBurstyAllSplit, MultitaskOmniglotBurstyTF\n",
    "from jaxl.datasets.wrappers import ContextDataset, FixedLengthContextDataset\n",
    "\n",
    "import jaxl.transforms as jaxl_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ContextDataset(\n",
    "#     MultitaskOmniglotBursty(\n",
    "#         dataset=torch_datasets.Omniglot(\n",
    "#             \"/home/bryanpu1/projects/icl/data\",\n",
    "#             background=True,\n",
    "#             download=False,\n",
    "#             transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         num_sequences=20,\n",
    "#         sequence_length=16,\n",
    "#         p_bursty=0.5,\n",
    "#         min_num_per_class=1,\n",
    "#     ),\n",
    "#     context_len=15,\n",
    "#     include_query_class=False,\n",
    "# )\n",
    "\n",
    "# dataset = FixedLengthContextDataset(\n",
    "#     MultitaskOmniglotBursty(\n",
    "#         dataset=torch_datasets.Omniglot(\n",
    "#             \"/home/bryanpu1/projects/icl/data\",\n",
    "#             background=True,\n",
    "#             download=False,\n",
    "#             transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         num_sequences=20,\n",
    "#         sequence_length=16,\n",
    "#         p_bursty=0.5,\n",
    "#         min_num_per_class=3,\n",
    "#     ),\n",
    "#     context_len=15,\n",
    "# )\n",
    "\n",
    "# dataset = FixedLengthContextDataset(\n",
    "#     MultitaskOmniglotNWayKShot(\n",
    "#         dataset=torch_datasets.Omniglot(\n",
    "#             \"/home/bryanpu1/projects/icl/data\",\n",
    "#             background=True,\n",
    "#             download=False,\n",
    "#             transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         num_sequences=20,\n",
    "#         sequence_length=9,\n",
    "#         k_way=4\n",
    "#     ),\n",
    "#     context_len=8,\n",
    "# )\n",
    "\n",
    "# dataset = FixedLengthContextDataset(\n",
    "#     MultitaskOmniglotBurstyAllSplit(\n",
    "#         train_dataset=torch_datasets.Omniglot(\n",
    "#             \"/home/bryanpu1/projects/icl/data\",\n",
    "#             background=True,\n",
    "#             download=False,\n",
    "#             transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         test_dataset=torch_datasets.Omniglot(\n",
    "#             \"/home/bryanpu1/projects/icl/data\",\n",
    "#             background=False,\n",
    "#             download=False,\n",
    "#             transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         num_holdout=10,\n",
    "#         train=True,\n",
    "#         num_sequences=20,\n",
    "#         sequence_length=16,\n",
    "#         p_bursty=0.5,\n",
    "#         min_num_per_class=3,\n",
    "#     ),\n",
    "#     context_len=15,\n",
    "# )\n",
    "\n",
    "dataset = FixedLengthContextDataset(\n",
<<<<<<< HEAD
    "    MultitaskOmniglotBurstyTF(\n",
    "        load_path=\"/home/bryanpu1/projects/icl/data/tf_omniglot-single_example-all.pkl\",\n",
    "        train=True,\n",
    "        num_holdout=10,\n",
    "        num_sequences=50,\n",
    "        sequence_length=9,\n",
    "        p_bursty=0.0,\n",
    "        noise_scale=0.1\n",
    "    ),\n",
    "    context_len=8,\n",
    ")\n",
    "\n",
    "# dataset = FixedLengthContextDataset(\n",
    "#     MultitaskOmniglotBursty(\n",
=======
    "    MultitaskOmniglotBursty(\n",
    "        dataset=torch_datasets.Omniglot(\n",
    "            \"/home/bryanpu1/projects/icl/data\",\n",
    "            background=True,\n",
    "            download=False,\n",
    "            transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "            target_transform=None,\n",
    "        ),\n",
    "        num_sequences=20,\n",
    "        sequence_length=16,\n",
    "        p_bursty=0.5,\n",
    "        min_num_per_class=3,\n",
    "    ),\n",
    "    context_len=15,\n",
    ")\n",
    "\n",
    "# dataset = FixedLengthContextDataset(\n",
    "#     MultitaskOmniglotNWayKShot(\n",
>>>>>>> main
    "#         dataset=torch_datasets.Omniglot(\n",
    "#             \"/home/bryanpu1/projects/icl/data\",\n",
    "#             background=True,\n",
    "#             download=False,\n",
<<<<<<< HEAD
    "#             transform=torch_transforms.Compose([jaxl_transforms.DefaultPILToImageTransform(), jaxl_transforms.Transpose(axes=(1, 2, 0)),]),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         num_sequences=1000000,\n",
    "#         sequence_length=9,\n",
    "#         p_bursty=1.0,\n",
    "#         min_num_per_class=1,\n",
    "#     ),\n",
    "#     context_len=8,\n",
    "# )"
=======
    "#             transform=jaxl_transforms.DefaultPILToImageTransform(),\n",
    "#             target_transform=None,\n",
    "#         ),\n",
    "#         num_sequences=20,\n",
    "#         sequence_length=9,\n",
    "#         k_way=4\n",
    "#     ),\n",
    "#     context_len=8,\n",
    "# )\n"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci, co, q, o = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_2, co_2, q_2, o_2 = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.allclose(ci, ci_2))\n",
    "print(np.allclose(co, co_2))\n",
    "print(np.allclose(q, q_2))\n",
    "print(np.allclose(o, o_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(o, axis=-1), np.argmax(co, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_2, co_2, q_2, o_2 = dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(o_2, axis=-1), np.argmax(co_2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci.shape, co.shape, q.shape, o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset._data[\"is_bursty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 2), layout=\"constrained\")\n",
    "subfigs = fig.subfigures(1, 2, width_ratios=[8, 1])\n",
    "\n",
    "ax = subfigs[0].subplots(1, 8)\n",
    "subfigs[0].suptitle(\"Context\")\n",
    "for idx, (img, output) in enumerate(zip(ci, co)):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].set_title(np.argmax(output))\n",
    "    ax[idx].axis('off')\n",
    "\n",
    "subfigs[1].suptitle(\"Query\")\n",
    "subfigs[1].set_facecolor('0.75')\n",
    "ax = subfigs[1].subplots(1, 1)\n",
    "ax.imshow(q[0])\n",
    "ax.set_title(\"?\")\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig(\"non_bursty_sequence-noise_scale_0.1.pdf\", format=\"pdf\", bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 9)\n",
    "\n",
    "for idx, (img, output) in enumerate(zip(ci_2, co_2)):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].set_title(np.argmax(output))\n",
    "    ax[idx].axis('off')\n",
    "ax[-1].imshow(q[0])\n",
    "ax[-1].set_title(np.argmax(o, axis=-1))\n",
    "ax[-1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "# print(dataset._data[\"is_bursty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(dataset)):\n",
    "    ci, co, q, o = dataset[ii]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 9)\n",
    "\n",
    "    for idx, (img, output) in enumerate(zip(ci, co)):\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(np.argmax(output))\n",
    "        ax[idx].axis('off')\n",
    "    ax[-1].imshow(q[0])\n",
    "    ax[-1].set_title(np.argmax(o, axis=-1))\n",
    "    ax[-1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FixedLengthContextDataset(\n",
    "    MultitaskOmniglotBursty(\n",
    "        dataset=torch_datasets.Omniglot(\n",
    "            \"/home/bryanpu1/projects/icl/data\",\n",
    "            background=True,\n",
    "            download=False,\n",
    "            transform=torch_transforms.Compose([jaxl_transforms.DefaultPILToImageTransform(), jaxl_transforms.Transpose(axes=(1, 2, 0)),]),\n",
    "            target_transform=None,\n",
    "        ),\n",
    "        num_sequences=100,\n",
    "        sequence_length=9,\n",
    "        p_bursty=1.0,\n",
    "        min_num_per_class=1,\n",
    "    ),\n",
    "    context_len=8,\n",
    ")\n",
    "    \n",
    "\n",
    "for ii in range(len(dataset)):\n",
    "    ci, co, q, o = dataset[ii]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 9)\n",
    "\n",
    "    for idx, (img, output) in enumerate(zip(ci, co)):\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(np.argmax(output))\n",
    "        ax[idx].axis('off')\n",
    "    ax[-1].imshow(q[0])\n",
    "    ax[-1].set_title(np.argmax(o, axis=-1))\n",
    "    ax[-1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import torchvision.datasets as torch_datasets\n",
    "\n",
    "import jaxl.transforms as jaxl_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"train\": {},\n",
    "    \"test\": {},\n",
    "}\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    ds = tfds.load(\n",
    "        'omniglot', split=split, as_supervised=True, shuffle_files=False)\n",
    "\n",
    "    def _extract_image(image, label):\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        return image, label\n",
    "\n",
    "    for image, label in ds.map(_extract_image):\n",
    "        label = label.numpy().astype(np.int32)\n",
    "        # Populate the dictionary of {label: image} entries.\n",
    "        # Only add to the dataset if that class doesn't already exist.\n",
    "        if label not in data[split]:\n",
    "            image = image.numpy()\n",
    "            data[split][label] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"train\"]), len(data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {**data[\"train\"], **data[\"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    {\n",
    "        \"data\": data,\n",
    "        \"targets\": np.array(list(data.keys())),\n",
    "        \"img_shape\": (105, 105, 1),\n",
    "    },\n",
    "    open(\"tf_omniglot-single_example-all.pkl\", \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(label), type(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
