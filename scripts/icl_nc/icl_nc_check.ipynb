{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Neural Collapse in Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets.mnist import construct_mnist\n",
    "from jaxl.datasets.wrappers import (\n",
    "    ContextDataset,\n",
    "    StandardSupervisedDataset,\n",
    "    FixedLengthContextDataset,\n",
    "    RepeatedContextDataset,\n",
    ")\n",
    "from jaxl.models import get_model\n",
    "from jaxl.models.common import get_activation\n",
    "from jaxl.models.modules import CNNModule, MLPModule\n",
    "from jaxl.plot_utils import set_size\n",
    "from jaxl.utils import parse_dict, get_device\n",
    "\n",
    "import _pickle as pickle\n",
    "import argparse\n",
    "import jax\n",
    "import jax.random as jrandom\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as torch_datasets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"gpu:2\"\n",
    "get_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_width_pt = 750.0\n",
    "mnist_path = \"/home/bryanpu1/projects/jaxl/\"\n",
    "\n",
    "# learner_path = \"/Users/chanb/research/personal/jaxl/{}\".format(\n",
    "#     \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-01-22-24_23_44_06-92243c9f-bd13-4f61-adef-b73ac5fdbc2e\"\n",
    "# )\n",
    "learner_path = \"/home/bryanpu1/projects/jaxl/{}\".format(\n",
    "    # \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-01-25-24_14_43_17-c7291ffc-8ce2-4765-a6b7-452a095e7c53\", # No permutation on label as tasks\n",
    "    # \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-random_label-01-25-24_17_03_48-49d56e3a-5702-4b5a-b7e5-d6fbcc9153ff\", # Trained for 10k epochs, with bs = 128\n",
    "    # \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-fixed_length-random_label-01-26-24_13_12_58-969855a4-434e-4acf-b4b3-58bff7006a67\" # Trained for 5k epochs, with bs = 32, full-context length\n",
    "    # \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-fixed_length-random_label-stratified-01-27-24_11_36_50-fcc760fe-8c33-47e8-a1af-4f1ee2fb7189\", # Stratified Sampling\n",
    "    \"jaxl/logs/debug/context_len_10-num_blocks_4-fixed_length-random_label-stratified-overfit-01-29-24_14_39_18-2ef13763-ead1-4646-88ab-1a0c3fb040e4\"\n",
    ")\n",
    "\n",
    "exp_name = \"-\".join(learner_path.split(\"/\")[-1].split(\"-\")[:-8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(learner_path: str):\n",
    "    config_path = os.path.join(learner_path, \"config.json\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "        config = parse_dict(config_dict)\n",
    "\n",
    "    model = get_model((1, 28, 28), (10,), config.model_config)\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        os.path.join(learner_path, \"models\"),\n",
    "        PyTreeCheckpointer(),\n",
    "    )\n",
    "\n",
    "    params = checkpoint_manager.restore(checkpoint_manager.latest_step())\n",
    "    params[CONST_MODEL_DICT][CONST_MODEL][CONST_POSITIONAL_ENCODING] = dict()\n",
    "\n",
    "    return params, model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, model, config = load_model(learner_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_labels(data_loader, num_tasks):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "\n",
    "    for batch_i, samples in enumerate(data_loader):\n",
    "        if batch_i >= num_tasks:\n",
    "            break\n",
    "\n",
    "        (context_inputs, context_outputs, queries, one_hot_labels) = samples\n",
    "        \n",
    "        outputs, _ = model.forward(\n",
    "            params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "            queries.numpy(),\n",
    "            {\n",
    "                CONST_CONTEXT_INPUT: context_inputs.numpy(),\n",
    "                CONST_CONTEXT_OUTPUT: context_outputs.numpy(),\n",
    "            }\n",
    "        )\n",
    "        preds = np.argmax(outputs, axis=-1)\n",
    "        labels = np.argmax(one_hot_labels, axis=-1)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "        all_outputs.append(outputs)\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_preds, all_labels, all_outputs\n",
    "\n",
    "\n",
    "def print_performance(all_preds, all_labels, sequence_length, context_len, output_dim, fixed_length):\n",
    "    conf_mat = confusion_matrix(all_labels, all_preds, labels=np.arange(output_dim))\n",
    "    acc = np.trace(conf_mat) / np.sum(conf_mat) * 100\n",
    "    print(\"Pretraining Accuracy: {}\".format(acc))\n",
    "\n",
    "    if not fixed_length:\n",
    "        reshaped_preds = all_preds.reshape((-1, sequence_length - 1))\n",
    "        reshaped_labels = all_labels.reshape((-1, sequence_length - 1))\n",
    "        for curr_context_len in range(context_len):\n",
    "            if curr_context_len < context_len - 1:\n",
    "                curr_preds = reshaped_preds[:, curr_context_len]\n",
    "                curr_labels = reshaped_labels[:, curr_context_len]\n",
    "            else:\n",
    "                curr_preds = reshaped_preds[:, curr_context_len:]\n",
    "                curr_labels = reshaped_labels[:, curr_context_len:]\n",
    "\n",
    "            curr_preds = curr_preds.reshape(-1)\n",
    "            curr_labels = curr_labels.reshape(-1)\n",
    "\n",
    "            curr_conf_mat = confusion_matrix(curr_labels, curr_preds, labels=np.arange(output_dim))\n",
    "            curr_acc = np.trace(curr_conf_mat) / np.sum(curr_conf_mat) * 100\n",
    "            print(\"Pretraining Accuracy with Context Length {} (Num Samples: {}): {}\".format(curr_context_len + 1, np.sum(curr_conf_mat), curr_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tasks = 10000\n",
    "context_len = config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len\n",
    "\n",
    "if hasattr(config.learner_config.dataset_config.dataset_kwargs.task_config, \"sequence_length\"):\n",
    "    sequence_length = config.learner_config.dataset_config.dataset_kwargs.task_config.sequence_length\n",
    "elif hasattr(config.learner_config.dataset_config.dataset_kwargs.task_config, \"num_queries\"):\n",
    "    sequence_length = config.learner_config.dataset_config.dataset_kwargs.task_config.num_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.learner_config.dataset_config.dataset_wrapper.type == \"ContextDataset\":\n",
    "    wrapper = ContextDataset\n",
    "    fixed_length = False\n",
    "elif config.learner_config.dataset_config.dataset_wrapper.type == \"FixedLengthContextDataset\":\n",
    "    wrapper = FixedLengthContextDataset\n",
    "    fixed_length = True\n",
    "elif config.learner_config.dataset_config.dataset_wrapper.type == \"RepeatedContextDataset\":\n",
    "    wrapper = RepeatedContextDataset\n",
    "    fixed_length = False\n",
    "else:\n",
    "    raise ValueError(\"Invalid Wrapper\")\n",
    "\n",
    "train_dataset = wrapper(\n",
    "    construct_mnist(\n",
    "        save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "        task_name=config.learner_config.dataset_config.dataset_kwargs.task_name,\n",
    "        task_config=config.learner_config.dataset_config.dataset_kwargs.task_config,\n",
    "        train=True,\n",
    "    ),\n",
    "    context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_dataset._dataset.sequence_length - 1 if hasattr(train_dataset._dataset, \"sequence_length\") else train_dataset._dataset.num_queries,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_i in range(2):\n",
    "    ci, co, q, l = train_dataset[task_i * 29 + 28]\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = 8\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for idx, (img, label) in enumerate(zip(ci, co)):\n",
    "        axes[idx // ncols, idx % ncols].imshow(img)\n",
    "        axes[idx // ncols, idx % ncols].set_title(np.argmax(label))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(q.numpy()[0])\n",
    "    plt.title(np.argmax(l))\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_labels, all_outputs = get_preds_labels(train_loader, num_tasks)\n",
    "print_performance(all_preds, all_labels, sequence_length + 1, context_len, train_dataset.output_dim[0], fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Context Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_task = 0\n",
    "num_tasks_to_plot = 10\n",
    "\n",
    "for task_i in range(num_tasks_to_plot):\n",
    "    sample_idx = (task_i + start_task) * (sequence_length - 1) + sequence_length - 2\n",
    "    imgs, outputs, query, label = train_dataset[sample_idx]\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = context_len // nrows\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.85, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for idx, (img, output) in enumerate(zip(imgs, outputs)):\n",
    "        axes[idx // ncols, idx % ncols].imshow(img)\n",
    "        axes[idx // ncols, idx % ncols].set_title(np.argmax(output))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(query.numpy()[0])\n",
    "    plt.title(\"GT: {}, Pred: {}\".format(np.argmax(label), all_preds[sample_idx]))\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fixed_length:\n",
    "    start_task = 0\n",
    "    num_tasks_to_plot = 10\n",
    "\n",
    "    ncols = 5\n",
    "    nrows = num_tasks_to_plot // ncols\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for task_i in range(num_tasks_to_plot):\n",
    "        imgs, outputs, _, _ = train_dataset[(task_i + start_task) * (sequence_length - 1)]\n",
    "        axes[task_i // ncols, task_i % ncols].imshow(imgs[-1])\n",
    "        axes[task_i // ncols, task_i % ncols].set_title(\"Perm: {}, GT: {}, Pred: {}\".format(\n",
    "            np.argmax(outputs[-1]),\n",
    "            all_labels[(task_i + start_task) * (sequence_length - 1)],\n",
    "            all_preds[(task_i + start_task) * (sequence_length - 1)])\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance on Standard MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = FixedLengthContextDataset(\n",
    "#     construct_mnist(\n",
    "#         save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "#         task_name=config.learner_config.dataset_config.dataset_kwargs.task_name,\n",
    "#         task_config=parse_dict({\n",
    "#             \"num_sequences\": 500000,\n",
    "#             \"sequence_length\": 30,\n",
    "#             \"num_queries\": 30,\n",
    "#             \"random_label\": False,\n",
    "#             \"save_path\": \"/home/bryanpu1/projects/jaxl/data/icl-mnist-seq_len_30-500k_tasks-test-stratified.pkl\"\n",
    "#         }),\n",
    "#         train=False,\n",
    "#     ),\n",
    "#     context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    "# )\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=test_dataset._dataset.sequence_length - 1,\n",
    "#     shuffle=False,\n",
    "#     drop_last=False,\n",
    "#     num_workers=4,\n",
    "# )\n",
    "\n",
    "test_dataset = RepeatedContextDataset(\n",
    "    construct_mnist(\n",
    "        save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "        task_name=config.learner_config.dataset_config.dataset_kwargs.task_name,\n",
    "        task_config=parse_dict({\n",
    "            \"num_sequences\": 500000,\n",
    "            \"num_queries\": 10,\n",
    "            \"random_label\": False,\n",
    "            \"save_path\": \"/home/bryanpu1/projects/jaxl/data/icl-mnist-seq_len_10-500k_tasks-test-stratified.pkl\"\n",
    "        }),\n",
    "        train=False,\n",
    "    ),\n",
    "    context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_dataset._dataset.num_queries,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_labels, all_outputs = get_preds_labels(test_loader, num_tasks)\n",
    "print_performance(all_preds, all_labels, sequence_length, context_len, test_dataset.output_dim[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_task = 200\n",
    "num_tasks_to_plot = 10\n",
    "\n",
    "for task_i in range(num_tasks_to_plot):\n",
    "    sample_idx = (task_i + start_task) * (sequence_length - 1) + sequence_length - 2\n",
    "    imgs, outputs, query, label = test_dataset[sample_idx]\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = context_len // nrows\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.85, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for idx, (img, output) in enumerate(zip(imgs, outputs)):\n",
    "        axes[idx // ncols, idx % ncols].imshow(img)\n",
    "        axes[idx // ncols, idx % ncols].set_title(np.argmax(output))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(query.numpy()[0])\n",
    "    plt.title(\"GT: {}, Pred: {}\".format(np.argmax(label), all_preds[sample_idx]))\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance on Random Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = wrapper(\n",
    "    construct_mnist(\n",
    "        save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "        task_name=config.learner_config.dataset_config.dataset_kwargs.task_name,\n",
    "        task_config=parse_dict({\n",
    "            \"num_sequences\": 500000,\n",
    "            \"sequence_length\": 30,\n",
    "            \"random_label\": True,\n",
    "            \"save_path\": '/home/bryanpu1/projects/jaxl/jaxl/data/icl-mnist-seq_len_30-500k_tasks-test-random_label.pkl'\n",
    "        }),\n",
    "        train=False,\n",
    "    ),\n",
    "    context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_dataset._dataset.sequence_length - 1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_labels, _ = get_preds_labels(test_loader, num_tasks)\n",
    "print_performance(all_preds, all_labels, sequence_length, context_len, test_dataset.output_dim[0], fixed_length=fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 5\n",
    "nrows = 200 // ncols\n",
    "fig, axes = plt.subplots(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "start_task = 0\n",
    "for task_i in range(200):\n",
    "    imgs, outputs, _, _ = test_dataset[(task_i + start_task) * (sequence_length - 1)]\n",
    "    axes[task_i // ncols, task_i % ncols].imshow(imgs[-1])\n",
    "    axes[task_i // ncols, task_i % ncols].set_title(\"Perm: {}, GT: {}, Pred: {}\".format(\n",
    "        np.argmax(outputs[-1]),\n",
    "        all_labels[(task_i + start_task) * (sequence_length - 1)],\n",
    "        all_preds[(task_i + start_task) * (sequence_length - 1)])\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Binary Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = wrapper(\n",
    "    construct_mnist(\n",
    "        save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "        task_name=CONST_MULTITASK_MNIST_RANDOM_BINARY,\n",
    "        task_config=parse_dict({\n",
    "            \"num_sequences\": 500000,\n",
    "            \"sequence_length\": 30,\n",
    "            \"save_path\": '/home/bryanpu1/projects/jaxl/jaxl/data/icl-mnist-seq_len_30-500k_tasks-test-random_binary.pkl'\n",
    "        }),\n",
    "        train=False,\n",
    "    ),\n",
    "    context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_dataset._dataset.sequence_length - 1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_labels, _ = get_preds_labels(test_loader, num_tasks)\n",
    "print_performance(all_preds, all_labels, sequence_length, context_len, test_dataset.output_dim[0], fixed_length=fixed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_task = 200\n",
    "num_tasks_to_plot = 10\n",
    "\n",
    "for task_i in range(num_tasks_to_plot):\n",
    "    sample_idx = (task_i + start_task) * (sequence_length - 1) + sequence_length - 2\n",
    "    imgs, outputs, query, label = test_dataset[sample_idx]\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = context_len // nrows\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.85, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for idx, (img, output) in enumerate(zip(imgs, outputs)):\n",
    "        axes[idx // ncols, idx % ncols].imshow(img)\n",
    "        axes[idx // ncols, idx % ncols].set_title(np.argmax(output))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(query.numpy()[0])\n",
    "    plt.title(\"GT: {}, Pred: {}\".format(np.argmax(label), all_preds[sample_idx]))\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(params, inputs, carries):\n",
    "    cnn_outs, cnn_states = CNNModule(\n",
    "        config.model_config.features,\n",
    "        config.model_config.kernel_sizes,\n",
    "        get_activation(CONST_RELU),\n",
    "    ).apply(\n",
    "        {\"params\": params[CONST_MODEL_DICT][CONST_MODEL][CONST_CNN][CONST_PARAMS]},\n",
    "        inputs,\n",
    "        capture_intermediates=True,\n",
    "        mutable=[\"cnn_latents\"]\n",
    "    )\n",
    "\n",
    "    cnn_outs = cnn_outs.reshape((len(cnn_outs), -1))\n",
    "\n",
    "    _, mlp_states = MLPModule(\n",
    "        config.model_config.layers,\n",
    "        get_activation(CONST_RELU),\n",
    "        get_activation(CONST_IDENTITY),\n",
    "    ).apply(\n",
    "        {\"params\": params[CONST_MODEL_DICT][CONST_MODEL][CONST_MLP][CONST_PARAMS]},\n",
    "        cnn_outs,\n",
    "        capture_intermediates=True,\n",
    "        mutable=[\"mlp_latents\"]\n",
    "    )\n",
    "\n",
    "    latents = OrderedDict()\n",
    "    for (states, key) in [\n",
    "        (cnn_states, \"cnn_latents\"),\n",
    "        (mlp_states, \"mlp_latents\"),\n",
    "    ]:\n",
    "        for state, state_val in states[key].items():\n",
    "            latents[state] = state_val\n",
    "    return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(mlp_1_latents, labels, step):\n",
    "    os.makedirs(\"./imgs/{}\".format(exp_name), exist_ok=True)\n",
    "    nrows = 1\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    unique_classes = np.unique(labels[\"train\"])\n",
    "\n",
    "    for ax_i, key in enumerate((\"train\", \"test\")):\n",
    "        for class_i in unique_classes:\n",
    "            class_idxes = np.where(labels[key] == class_i)[0]\n",
    "            axes[ax_i].scatter(\n",
    "                mlp_1_latents[key][class_idxes, 0],\n",
    "                mlp_1_latents[key][class_idxes, 1],\n",
    "                label=\"Class {}\".format(class_i) if ax_i == 0 else \"\",\n",
    "                alpha=0.5,\n",
    "                s=1\n",
    "            )\n",
    "        axes[ax_i].set_title(key)\n",
    "    fig.legend()\n",
    "    fig.suptitle(\"Model @ epoch {}\".format(step))\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"./imgs/{}/nc-step_{:08d}.png\".format(exp_name, step), format=\"png\", bbox_inches=\"tight\", dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for (step, params) in all_params:\n",
    "    mlp_1_latents = {\n",
    "        \"train\": [],\n",
    "        \"test\": [],\n",
    "    }\n",
    "    labels = {\n",
    "        \"train\": [],\n",
    "        \"test\": [], \n",
    "    }\n",
    "    all_latents = {\n",
    "        \"train\": {},\n",
    "        \"test\": {}\n",
    "    }\n",
    "\n",
    "    for key, dataloader in ((\"train\", train_dataloader), (\"test\", test_dataloader)):\n",
    "        for batch_i, (inputs, carries, outputs, _) in enumerate(iter(dataloader)):\n",
    "            latents = get_latent(params, inputs, carries)\n",
    "            mlp_1_latents[key].append(latents[\"mlp_{}\".format(len(config.model_config.layers) - 1)][0])\n",
    "            labels[key].append(outputs)\n",
    "            for k in latents:\n",
    "                all_latents[key].setdefault(k, [])\n",
    "                all_latents[key][k].append(latents[k][0])\n",
    "\n",
    "        mlp_1_latents[key] = np.concatenate(mlp_1_latents[key], axis=0)\n",
    "        labels[key] = np.concatenate(labels[key], axis=0)\n",
    "        all_latents[key] = {k: np.concatenate(all_latents[key][k]) for k in all_latents[key]}\n",
    "    plot(mlp_1_latents, labels, step)\n",
    "    results[step] = {\n",
    "        \"latents\": all_latents,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "with imageio.get_writer(\"./nc-{}.gif\".format(exp_name), mode='I', duration=100) as writer:\n",
    "    img_dir = \"./imgs/{}\".format(exp_name)\n",
    "    for filename in sorted(os.listdir(img_dir)):\n",
    "        if not filename.startswith(\"nc-step\"):\n",
    "            continue\n",
    "        image = imageio.imread(os.path.join(img_dir, filename))\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Neural Collapse Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_results = {}\n",
    "for step, step_res in results.items():\n",
    "    valid_classes = np.unique(step_res[\"labels\"][\"train\"])\n",
    "    nc_results.setdefault(step, {})\n",
    "    # for phase, phase_latents in step_res[\"latents\"].items():\n",
    "    for phase in [\"train\"]:\n",
    "        phase_latents = step_res[\"latents\"][phase]\n",
    "        for layer, curr_latents in phase_latents.items():\n",
    "            if layer.startswith(\"cnn\"):\n",
    "                continue\n",
    "            nc_results[step].setdefault(layer, {})\n",
    "            nc_results[step][layer][\"global_means\"] = np.mean(curr_latents, axis=0)\n",
    "            offset = (curr_latents - nc_results[step][layer][\"global_means\"][None])[..., None]\n",
    "            nc_results[step][layer][\"train_total_cov\"] = np.mean(offset @ np.transpose(offset, (0, 2, 1)), axis=0)\n",
    "\n",
    "            nc_results[step][layer][\"class_means\"] = {}\n",
    "            for class_i in valid_classes:\n",
    "                class_idxes = np.where(step_res[\"labels\"][phase] == class_i)[0]\n",
    "                nc_results[step][layer][\"class_means\"][class_i] = np.mean(curr_latents[class_idxes], axis=0)\n",
    "            between_class_offset = np.vstack([nc_results[step][layer][\"class_means\"][class_i] - nc_results[step][layer][\"global_means\"] for class_i in valid_classes])[..., None]\n",
    "            nc_results[step][layer][\"between_class_cov\"] = np.mean(between_class_offset @ np.transpose(between_class_offset, (0, 2, 1)), axis=0)\n",
    "            nc_results[step][layer][\"within_class_cov\"] = np.mean(\n",
    "                np.concatenate(\n",
    "                    [curr_latents[np.where(step_res[\"labels\"][phase] == class_i)[0]] - nc_results[step][layer][\"class_means\"][class_i][None] for class_i in valid_classes],\n",
    "                    axis=0\n",
    "                ),\n",
    "                axis=0\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_map(lambda x: x.shape, nc_results[step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(nc_results[1])\n",
    "ncols = 1\n",
    "fig, axes = plt.subplots(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "\n",
    "for ax_i, layer in enumerate(nc_results[1]):\n",
    "    within_class_cov = np.array([nc_results[step][layer][\"within_class_cov\"] for step in nc_results])\n",
    "    for dim_i in range(within_class_cov.shape[1]):\n",
    "        axes[ax_i].plot(\n",
    "            nc_results.keys(),\n",
    "            within_class_cov[:, dim_i],\n",
    "            label=\"dim. {}\".format(dim_i)\n",
    "        )\n",
    "    axes[ax_i].set_title(layer)\n",
    "    axes[ax_i].legend()\n",
    "fig.suptitle(\"NC 1 Condition\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
