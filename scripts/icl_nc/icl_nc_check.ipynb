{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Neural Collapse in Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets.mnist import construct_mnist\n",
    "from jaxl.datasets.wrappers import ContextDataset\n",
    "from jaxl.models import get_model\n",
    "from jaxl.models.common import get_activation\n",
    "from jaxl.models.modules import CNNModule, MLPModule\n",
    "from jaxl.plot_utils import set_size\n",
    "from jaxl.utils import parse_dict, get_device\n",
    "\n",
    "import _pickle as pickle\n",
    "import argparse\n",
    "import jax\n",
    "import jax.random as jrandom\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as torch_datasets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"gpu:0,1,2\"\n",
    "get_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_width_pt = 750.0\n",
    "\n",
    "# learner_path = \"/Users/chanb/research/personal/jaxl/{}\".format(\n",
    "#     \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-01-22-24_23_44_06-92243c9f-bd13-4f61-adef-b73ac5fdbc2e\"\n",
    "# )\n",
    "learner_path = \"/home/bryanpu1/projects/jaxl/{}\".format(\n",
    "    \"jaxl/logs/icl-mnist/context_len_16-num_blocks_8-random_label-01-23-24_20_14_30-917f353b-afba-44de-ba8f-5de4242ffa27\"\n",
    ")\n",
    "\n",
    "exp_name = \"-\".join(learner_path.split(\"/\")[-1].split(\"-\")[:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(learner_path: str):\n",
    "    config_path = os.path.join(learner_path, \"config.json\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "        config = parse_dict(config_dict)\n",
    "\n",
    "    model = get_model((1, 28, 28), (10,), config.model_config)\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        os.path.join(learner_path, \"models\"),\n",
    "        PyTreeCheckpointer(),\n",
    "    )\n",
    "\n",
    "    params = checkpoint_manager.restore(checkpoint_manager.latest_step())\n",
    "    params[CONST_MODEL_DICT][CONST_MODEL][CONST_POSITIONAL_ENCODING] = dict()\n",
    "\n",
    "    return params, model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 13:28:45.553106: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "CUDA backend failed to initialize: FAILED_PRECONDITION: No visible GPU devices. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/bryanpu1/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/type_handlers.py:1472: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SingleDeviceSharding with Device=cuda:0 was not found in jax.local_devices().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m params, model, config \u001b[39m=\u001b[39m load_model(learner_path)\n",
      "\u001b[1;32m/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m get_model((\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), (\u001b[39m10\u001b[39m,), config\u001b[39m.\u001b[39mmodel_config)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m checkpoint_manager \u001b[39m=\u001b[39m CheckpointManager(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(learner_path, \u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     PyTreeCheckpointer(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m params \u001b[39m=\u001b[39m checkpoint_manager\u001b[39m.\u001b[39;49mrestore(checkpoint_manager\u001b[39m.\u001b[39;49mlatest_step())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m params[CONST_MODEL_DICT][CONST_MODEL][CONST_POSITIONAL_ENCODING] \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalient2.cs.ualberta.ca/home/bryanpu1/projects/jaxl/scripts/icl_nc/icl_nc_check.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m params, model, config\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/checkpoint_manager.py:552\u001b[0m, in \u001b[0;36mCheckpointManager.restore\u001b[0;34m(self, step, items, restore_kwargs, directory)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_item:\n\u001b[1;32m    550\u001b[0m   restore_kwargs \u001b[39m=\u001b[39m {DEFAULT_ITEM_NAME: restore_kwargs}\n\u001b[0;32m--> 552\u001b[0m restored_items \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_restore_impl(\n\u001b[1;32m    553\u001b[0m     step, items, restore_kwargs, directory\u001b[39m=\u001b[39;49mdirectory)\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_item:\n\u001b[1;32m    556\u001b[0m   \u001b[39mreturn\u001b[39;00m restored_items[DEFAULT_ITEM_NAME]\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/checkpoint_manager.py:584\u001b[0m, in \u001b[0;36mCheckpointManager._restore_impl\u001b[0;34m(self, step, items, restore_kwargs, directory)\u001b[0m\n\u001b[1;32m    582\u001b[0m   item \u001b[39m=\u001b[39m items\u001b[39m.\u001b[39mget(item_name, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    583\u001b[0m   kwargs \u001b[39m=\u001b[39m restore_kwargs\u001b[39m.\u001b[39mget(item_name, {})\n\u001b[0;32m--> 584\u001b[0m   restored[item_name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_checkpointers[item_name]\u001b[39m.\u001b[39;49mrestore(\n\u001b[1;32m    585\u001b[0m       path, item\u001b[39m=\u001b[39;49mitem, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m restored\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/checkpointer.py:165\u001b[0m, in \u001b[0;36mCheckpointer.restore\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFound incomplete checkpoint at \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    164\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mRestoring item from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, directory)\n\u001b[0;32m--> 165\u001b[0m restored \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_restore_with_args(directory, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mFinished restoring checkpoint from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, directory)\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m restored\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/checkpointer.py:103\u001b[0m, in \u001b[0;36mCheckpointer._restore_with_args\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m ckpt_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_checkpoint_args(\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m ckpt_args:\n\u001b[0;32m--> 103\u001b[0m   restored \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handler\u001b[39m.\u001b[39;49mrestore(directory, args\u001b[39m=\u001b[39;49mckpt_args)\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m   restored \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handler\u001b[39m.\u001b[39mrestore(directory, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/pytree_checkpoint_handler.py:1073\u001b[0m, in \u001b[0;36mPyTreeCheckpointHandler.restore\u001b[0;34m(self, directory, item, restore_args, transforms, transforms_default_to_original, legacy_transform_fn, args)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[39m# If metadata file was missing in the checkpoint, we need to decide\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[39m# restore_type based on RestoreArgs.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m structure \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m   1070\u001b[0m     _maybe_set_default_restore_types, structure, checkpoint_restore_args\n\u001b[1;32m   1071\u001b[0m )\n\u001b[0;32m-> 1073\u001b[0m restored_item \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1074\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_deserialize(structure, param_infos, checkpoint_restore_args)\n\u001b[1;32m   1075\u001b[0m )\n\u001b[1;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m legacy_transform_fn:\n\u001b[1;32m   1078\u001b[0m   restored_item \u001b[39m=\u001b[39m _transform_checkpoint(\n\u001b[1;32m   1079\u001b[0m       item,\n\u001b[1;32m   1080\u001b[0m       restored_item,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1083\u001b[0m       transforms_default_to_original,\n\u001b[1;32m   1084\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m task \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(main)\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m loop\u001b[39m.\u001b[39;49mrun_until_complete(task)\n\u001b[1;32m     32\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m task\u001b[39m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/nest_asyncio.py:99\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[1;32m     97\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mEvent loop stopped before Future completed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/asyncio/tasks.py:258\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    256\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    257\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39;49mthrow(exc)\n\u001b[1;32m    259\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_must_cancel:\n\u001b[1;32m    261\u001b[0m         \u001b[39m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/pytree_checkpoint_handler.py:903\u001b[0m, in \u001b[0;36mPyTreeCheckpointHandler._maybe_deserialize\u001b[0;34m(self, structure, param_infos, restore_args)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39mfor\u001b[39;00m request \u001b[39min\u001b[39;00m batch_requests:\n\u001b[1;32m    900\u001b[0m   deserialized_batches_ops\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    901\u001b[0m       request\u001b[39m.\u001b[39mhandler\u001b[39m.\u001b[39mdeserialize(request\u001b[39m.\u001b[39minfos, request\u001b[39m.\u001b[39margs)\n\u001b[1;32m    902\u001b[0m   )\n\u001b[0;32m--> 903\u001b[0m deserialized_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mdeserialized_batches_ops)\n\u001b[1;32m    905\u001b[0m flat_restored \u001b[39m=\u001b[39m {}\n\u001b[1;32m    906\u001b[0m \u001b[39mfor\u001b[39;00m request, deserialized \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch_requests, deserialized_batches):\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/asyncio/tasks.py:328\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__wakeup\u001b[39m(\u001b[39mself\u001b[39m, future):\n\u001b[1;32m    327\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m         future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    329\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    330\u001b[0m         \u001b[39m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/asyncio/tasks.py:256\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    257\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/type_handlers.py:1492\u001b[0m, in \u001b[0;36mArrayHandler.deserialize\u001b[0;34m(self, infos, args)\u001b[0m\n\u001b[1;32m   1489\u001b[0m   serialized_string \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m t\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1490\u001b[0m   \u001b[39mif\u001b[39;00m serialized_string:\n\u001b[1;32m   1491\u001b[0m     sharding \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1492\u001b[0m         _deserialize_sharding_from_json_string(serialized_string\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m   1493\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m     )\n\u001b[1;32m   1495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1496\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnable to deserialize sharding.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/jaxl_cudnn12/lib/python3.9/site-packages/orbax/checkpoint/type_handlers.py:162\u001b[0m, in \u001b[0;36m_deserialize_sharding_from_json_string\u001b[0;34m(sharding_string)\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[39mif\u001b[39;00m device \u001b[39m:=\u001b[39m _deserialize_sharding_from_json_string\u001b[39m.\u001b[39mdevice_map\u001b[39m.\u001b[39mget(\n\u001b[1;32m    158\u001b[0m       device_str, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    159\u001b[0m   ):\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m SingleDeviceSharding(device)\n\u001b[0;32m--> 162\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    163\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mShardingTypes\u001b[39m.\u001b[39mSINGLE_DEVICE_SHARDING\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m with\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    164\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Device=\u001b[39m\u001b[39m{\u001b[39;00mdevice_str\u001b[39m}\u001b[39;00m\u001b[39m was not found in jax.local_devices().\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    165\u001b[0m   )\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mSharding types other than `jax.sharding.NamedSharding` have not been \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mimplemented.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    171\u001b[0m   )\n",
      "\u001b[0;31mValueError\u001b[0m: SingleDeviceSharding with Device=cuda:0 was not found in jax.local_devices()."
     ]
    }
   ],
   "source": [
    "params, model, config = load_model(learner_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ContextDataset(\n",
    "    construct_mnist(\n",
    "        save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "        task_name=config.learner_config.dataset_config.dataset_kwargs.task_name,\n",
    "        task_config=parse_dict({\n",
    "            \"num_sequences\": 30,\n",
    "            \"sequence_length\": 30,\n",
    "            \"save_path\": \"./data/icl-mnist-seq_len_30-30_tasks-test-fine_grain.pkl\"\n",
    "        }),\n",
    "        train=False,\n",
    "    ),\n",
    "    context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    ")\n",
    "\n",
    "test_dataset = ContextDataset(\n",
    "    construct_mnist(\n",
    "        save_path=config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "        task_name=CONST_MULTITASK_MNIST_RANDOM_BINARY,\n",
    "        task_config=parse_dict({\n",
    "            \"num_sequences\": 30,\n",
    "            \"sequence_length\": 30,\n",
    "            \"save_path\": \"./data/icl-mnist-seq_len_30-30_tasks-test-random_binary.pkl\"\n",
    "        }),\n",
    "        train=False,\n",
    "    ),\n",
    "    context_len=config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Out-of-task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_inputs, context_outputs, queries, labels = train_dataset[0]\n",
    "# print(\n",
    "#     context_inputs.shape,\n",
    "#     context_outputs.shape,\n",
    "#     queries.shape,\n",
    "#     labels.shape\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_idx in np.arange(28, len(test_dataset), 29):\n",
    "    context_inputs, context_outputs, queries, labels = test_dataset[sample_idx]\n",
    "    outputs, _ = model.forward(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "        queries.numpy()[None],\n",
    "        {\n",
    "            CONST_CONTEXT_INPUT: context_inputs[None],\n",
    "            CONST_CONTEXT_OUTPUT: context_outputs[None],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = len(context_inputs) // 2\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for idx, img in enumerate(context_inputs):\n",
    "        axes[idx % 2, idx // 2].imshow(img)\n",
    "        axes[idx % 2, idx // 2].set_title(\"Label: {}\".format(np.argmax(context_outputs[idx])))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Prediction: {} - Label: {}\".format(np.argmax(outputs[0, :2]), np.argmax(labels)))\n",
    "    plt.imshow(queries[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(params, inputs, carries):\n",
    "    cnn_outs, cnn_states = CNNModule(\n",
    "        config.model_config.features,\n",
    "        config.model_config.kernel_sizes,\n",
    "        get_activation(CONST_RELU),\n",
    "    ).apply(\n",
    "        {\"params\": params[CONST_MODEL_DICT][CONST_MODEL][CONST_CNN][CONST_PARAMS]},\n",
    "        inputs,\n",
    "        capture_intermediates=True,\n",
    "        mutable=[\"cnn_latents\"]\n",
    "    )\n",
    "\n",
    "    cnn_outs = cnn_outs.reshape((len(cnn_outs), -1))\n",
    "\n",
    "    _, mlp_states = MLPModule(\n",
    "        config.model_config.layers,\n",
    "        get_activation(CONST_RELU),\n",
    "        get_activation(CONST_IDENTITY),\n",
    "    ).apply(\n",
    "        {\"params\": params[CONST_MODEL_DICT][CONST_MODEL][CONST_MLP][CONST_PARAMS]},\n",
    "        cnn_outs,\n",
    "        capture_intermediates=True,\n",
    "        mutable=[\"mlp_latents\"]\n",
    "    )\n",
    "\n",
    "    latents = OrderedDict()\n",
    "    for (states, key) in [\n",
    "        (cnn_states, \"cnn_latents\"),\n",
    "        (mlp_states, \"mlp_latents\"),\n",
    "    ]:\n",
    "        for state, state_val in states[key].items():\n",
    "            latents[state] = state_val\n",
    "    return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(mlp_1_latents, labels, step):\n",
    "    os.makedirs(\"./imgs/{}\".format(exp_name), exist_ok=True)\n",
    "    nrows = 1\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    unique_classes = np.unique(labels[\"train\"])\n",
    "\n",
    "    for ax_i, key in enumerate((\"train\", \"test\")):\n",
    "        for class_i in unique_classes:\n",
    "            class_idxes = np.where(labels[key] == class_i)[0]\n",
    "            axes[ax_i].scatter(\n",
    "                mlp_1_latents[key][class_idxes, 0],\n",
    "                mlp_1_latents[key][class_idxes, 1],\n",
    "                label=\"Class {}\".format(class_i) if ax_i == 0 else \"\",\n",
    "                alpha=0.5,\n",
    "                s=1\n",
    "            )\n",
    "        axes[ax_i].set_title(key)\n",
    "    fig.legend()\n",
    "    fig.suptitle(\"Model @ epoch {}\".format(step))\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"./imgs/{}/nc-step_{:08d}.png\".format(exp_name, step), format=\"png\", bbox_inches=\"tight\", dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for (step, params) in all_params:\n",
    "    mlp_1_latents = {\n",
    "        \"train\": [],\n",
    "        \"test\": [],\n",
    "    }\n",
    "    labels = {\n",
    "        \"train\": [],\n",
    "        \"test\": [], \n",
    "    }\n",
    "    all_latents = {\n",
    "        \"train\": {},\n",
    "        \"test\": {}\n",
    "    }\n",
    "\n",
    "    for key, dataloader in ((\"train\", train_dataloader), (\"test\", test_dataloader)):\n",
    "        for batch_i, (inputs, carries, outputs, _) in enumerate(iter(dataloader)):\n",
    "            latents = get_latent(params, inputs, carries)\n",
    "            mlp_1_latents[key].append(latents[\"mlp_{}\".format(len(config.model_config.layers) - 1)][0])\n",
    "            labels[key].append(outputs)\n",
    "            for k in latents:\n",
    "                all_latents[key].setdefault(k, [])\n",
    "                all_latents[key][k].append(latents[k][0])\n",
    "\n",
    "        mlp_1_latents[key] = np.concatenate(mlp_1_latents[key], axis=0)\n",
    "        labels[key] = np.concatenate(labels[key], axis=0)\n",
    "        all_latents[key] = {k: np.concatenate(all_latents[key][k]) for k in all_latents[key]}\n",
    "    plot(mlp_1_latents, labels, step)\n",
    "    results[step] = {\n",
    "        \"latents\": all_latents,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "with imageio.get_writer(\"./nc-{}.gif\".format(exp_name), mode='I', duration=100) as writer:\n",
    "    img_dir = \"./imgs/{}\".format(exp_name)\n",
    "    for filename in sorted(os.listdir(img_dir)):\n",
    "        if not filename.startswith(\"nc-step\"):\n",
    "            continue\n",
    "        image = imageio.imread(os.path.join(img_dir, filename))\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Neural Collapse Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_results = {}\n",
    "for step, step_res in results.items():\n",
    "    valid_classes = np.unique(step_res[\"labels\"][\"train\"])\n",
    "    nc_results.setdefault(step, {})\n",
    "    # for phase, phase_latents in step_res[\"latents\"].items():\n",
    "    for phase in [\"train\"]:\n",
    "        phase_latents = step_res[\"latents\"][phase]\n",
    "        for layer, curr_latents in phase_latents.items():\n",
    "            if layer.startswith(\"cnn\"):\n",
    "                continue\n",
    "            nc_results[step].setdefault(layer, {})\n",
    "            nc_results[step][layer][\"global_means\"] = np.mean(curr_latents, axis=0)\n",
    "            offset = (curr_latents - nc_results[step][layer][\"global_means\"][None])[..., None]\n",
    "            nc_results[step][layer][\"train_total_cov\"] = np.mean(offset @ np.transpose(offset, (0, 2, 1)), axis=0)\n",
    "\n",
    "            nc_results[step][layer][\"class_means\"] = {}\n",
    "            for class_i in valid_classes:\n",
    "                class_idxes = np.where(step_res[\"labels\"][phase] == class_i)[0]\n",
    "                nc_results[step][layer][\"class_means\"][class_i] = np.mean(curr_latents[class_idxes], axis=0)\n",
    "            between_class_offset = np.vstack([nc_results[step][layer][\"class_means\"][class_i] - nc_results[step][layer][\"global_means\"] for class_i in valid_classes])[..., None]\n",
    "            nc_results[step][layer][\"between_class_cov\"] = np.mean(between_class_offset @ np.transpose(between_class_offset, (0, 2, 1)), axis=0)\n",
    "            nc_results[step][layer][\"within_class_cov\"] = np.mean(\n",
    "                np.concatenate(\n",
    "                    [curr_latents[np.where(step_res[\"labels\"][phase] == class_i)[0]] - nc_results[step][layer][\"class_means\"][class_i][None] for class_i in valid_classes],\n",
    "                    axis=0\n",
    "                ),\n",
    "                axis=0\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_map(lambda x: x.shape, nc_results[step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(nc_results[1])\n",
    "ncols = 1\n",
    "fig, axes = plt.subplots(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "\n",
    "for ax_i, layer in enumerate(nc_results[1]):\n",
    "    within_class_cov = np.array([nc_results[step][layer][\"within_class_cov\"] for step in nc_results])\n",
    "    for dim_i in range(within_class_cov.shape[1]):\n",
    "        axes[ax_i].plot(\n",
    "            nc_results.keys(),\n",
    "            within_class_cov[:, dim_i],\n",
    "            label=\"dim. {}\".format(dim_i)\n",
    "        )\n",
    "    axes[ax_i].set_title(layer)\n",
    "    axes[ax_i].legend()\n",
    "fig.suptitle(\"NC 1 Condition\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
