{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Neural Collapse in Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets.mnist import construct_mnist\n",
    "from jaxl.datasets.wrappers import StandardSupervisedDataset\n",
    "from jaxl.learning_utils import get_learner\n",
    "from jaxl.models.common import get_activation\n",
    "from jaxl.models.modules import CNNModule, MLPModule\n",
    "from jaxl.plot_utils import set_size\n",
    "from jaxl.utils import parse_dict, get_device\n",
    "\n",
    "import _pickle as pickle\n",
    "import argparse\n",
    "import jax\n",
    "import jax.random as jrandom\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as torch_datasets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "get_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_width_pt = 750.0\n",
    "\n",
    "learner_path = \"/Users/chanb/research/personal/jaxl/{}\".format(\n",
    "    \"jaxl/logs/nc-mnist/cnn-01-19-24_19_37_18-8c04f541-01bc-4346-be64-5581bceb4cc2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(learner_path: str):\n",
    "    config_path = os.path.join(learner_path, \"config.json\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "        config = parse_dict(config_dict)\n",
    "\n",
    "    learner = get_learner(\n",
    "        config.learner_config, config.model_config, config.optimizer_config\n",
    "    )\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        os.path.join(learner_path, \"models\"),\n",
    "        PyTreeCheckpointer(),\n",
    "    )\n",
    "\n",
    "    params = checkpoint_manager.restore(checkpoint_manager.latest_step())\n",
    "    all_params = [(step, checkpoint_manager.restore(step)) for step in checkpoint_manager.all_steps()]\n",
    "    model = learner._model\n",
    "    return params, model, config, all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, model, config, all_params = load_model(learner_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StandardSupervisedDataset(construct_mnist(\n",
    "    config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "    train=True,\n",
    "))\n",
    "\n",
    "test_dataset = StandardSupervisedDataset(construct_mnist(\n",
    "    config.learner_config.dataset_config.dataset_kwargs.save_path,\n",
    "    train=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(params, inputs, carries):\n",
    "    cnn_outs, cnn_states = CNNModule(\n",
    "        config.model_config.features,\n",
    "        config.model_config.kernel_sizes,\n",
    "        get_activation(CONST_RELU),\n",
    "    ).apply(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL][CONST_CNN],\n",
    "        inputs,\n",
    "        capture_intermediates=True,\n",
    "        mutable=[\"cnn_latents\"]\n",
    "    )\n",
    "\n",
    "    cnn_outs = cnn_outs.reshape((len(cnn_outs), -1))\n",
    "\n",
    "    _, mlp_states = MLPModule(\n",
    "        config.model_config.layers,\n",
    "        get_activation(CONST_RELU),\n",
    "        get_activation(CONST_IDENTITY),\n",
    "    ).apply(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL][CONST_MLP],\n",
    "        cnn_outs,\n",
    "        capture_intermediates=True,\n",
    "        mutable=[\"mlp_latents\"]\n",
    "    )\n",
    "\n",
    "    latents = OrderedDict()\n",
    "    for (states, key) in [\n",
    "        (cnn_states, \"cnn_latents\"),\n",
    "        (mlp_states, \"mlp_latents\"),\n",
    "    ]:\n",
    "        for state, state_val in states[key].items():\n",
    "            latents[state] = state_val\n",
    "    return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(mlp_1_latents, labels, step):\n",
    "    nrows = ncols = 1\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    unique_classes = np.unique(labels)\n",
    "\n",
    "    for class_i in unique_classes:\n",
    "        class_idxes = np.where(labels == class_i)[0]\n",
    "        axes.scatter(\n",
    "            mlp_1_latents[class_idxes, 0],\n",
    "            mlp_1_latents[class_idxes, 1],\n",
    "            label=\"Class {}\".format(class_i),\n",
    "            alpha=0.5\n",
    "        )\n",
    "    fig.legend()\n",
    "    fig.suptitle(\"Model @ epoch {}\".format(step))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (step, params) in all_params:\n",
    "    mlp_1_latents = []\n",
    "    labels = []\n",
    "    for inputs, carries, outputs, _ in iter(train_dataloader):\n",
    "        latents = get_latent(params, inputs, carries)\n",
    "        mlp_1_latents.append(latents[\"mlp_1\"][0])\n",
    "        labels.append(outputs)\n",
    "\n",
    "    mlp_1_latents = np.concatenate(mlp_1_latents, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    plot(mlp_1_latents, labels, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
