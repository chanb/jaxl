{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate ICL Model on the Omniglot Classification Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets import get_dataset\n",
    "from jaxl.datasets.wrappers import (\n",
    "    ContextDataset,\n",
    "    StandardSupervisedDataset,\n",
    "    FixedLengthContextDataset,\n",
    "    RepeatedContextDataset,\n",
    ")\n",
    "from jaxl.models import load_config, load_model, get_model, get_activation\n",
    "from jaxl.plot_utils import set_size\n",
    "from jaxl.utils import parse_dict, get_device\n",
    "\n",
    "import _pickle as pickle\n",
    "import copy\n",
    "import jax\n",
    "import jax.random as jrandom\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as torch_datasets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"gpu:0\"\n",
    "get_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_width_pt = 750.0\n",
    "\n",
    "base_path = \"/home/bryanpu1/projects/icl/jaxl/\"\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "log_path = os.path.join(base_path, \"jaxl/logs\")\n",
    "project_name = \"icl-omniglot\"\n",
    "# ablation_name = \"bursty_ablation\"\n",
    "# ablation_name = \"bursty_ablation-fixed_length\"\n",
    "ablation_name = \"pixel_noise_ablation/all_omniglot-pixel_noise_0.1\"\n",
    "# ablation_name = \"\"\n",
    "run_name = (\n",
    "    # \"bursty_0.0-context_len_8-03-04-24_11_06_22-7a6e6aca-b77d-401d-842e-9bdddc5eeaa1\"\n",
    "    # \"bursty_0.5-context_len_8-03-04-24_11_06_15-b2563eae-7e83-4b45-aa00-eb6d770c5fc5\"\n",
    "    # \"bursty_1.0-context_len_8-03-04-24_11_06_28-33b976d7-422f-4d66-ae9f-3bd86f1bd451\"\n",
    "\n",
    "    # \"bursty_0.0-context_len_8-batch_norm-03-05-24_07_56_37-1c4d12c3-4363-4cb6-bcda-6b25932cc9ea\"\n",
    "    # \"bursty_0.5-context_len_8-batch_norm-03-05-24_07_55_58-a4d55433-45e2-406f-869a-ccd082c2b983\"\n",
    "    # \"bursty_1.0-context_len_8-batch_norm-03-05-24_07_57_05-f318fcb7-b332-4719-8917-028876194a02\"\n",
    "\n",
    "    # \"bursty_0.0-context_len_8-batch_norm-no_aug-03-06-24_09_04_24-b772c27c-1592-4be2-a24e-b1b1c56e4761\"\n",
    "    # \"bursty_0.5-context_len_8-batch_norm-no_aug-03-06-24_09_04_50-25fc1859-2f1c-4758-8d6a-a893d59425d7\"\n",
    "    # \"bursty_1.0-context_len_8-batch_norm-no_aug-03-06-24_09_04_16-feec38cd-486e-4885-a108-961c93061a7b\"\n",
    "\n",
    "    # \"bursty_1.0-context_len_8-batch_norm-num_blocks_12-03-08-24_11_59_04-52544705-d03f-4781-b2ce-98a98f8d487d\"\n",
    "    # \"bursty_1.0-context_len_8-batch_norm-num_blocks_12-larger_dataset-03-08-24_12_59_55-f4498c2d-df47-45d0-a817-41db45c76d7a\"\n",
    "    # \"bursty_1.0-context_len_8-batch_norm-num_blocks_12-no_aug-larger_dataset-03-08-24_13_25_46-1c0e931a-8989-4a4a-8db5-ceba093418e4\"\n",
    "\n",
    "    # \"bursty_0.0-context_len_8-batch_norm-larger_dataset-03-09-24_22_11_33-6da36b91-6f7e-4950-98d3-f81c0ad471e5\"\n",
    "    # \"bursty_0.5-context_len_8-batch_norm-larger_dataset-03-09-24_22_11_22-f752093b-3f9f-413c-956a-8965896f52a4\"\n",
    "    # \"bursty_1.0-context_len_8-batch_norm-larger_dataset-03-09-24_22_11_11-5ac8c8f6-ad00-46c9-92eb-469b22d7979d\"\n",
    "\n",
    "    # Pixel Noise\n",
    "    # \"bursty_0.0-pixel_noise_0.1-03-14-24_12_01_47-93f2a221-43a3-4cf5-870c-627608e759b6\"\n",
    "    # \"bursty_0.5-pixel_noise_0.1-03-14-24_11_53_05-d84ee8c5-24ca-486e-ae76-9553b15a35a6\"\n",
    "    # \"bursty_1.0-pixel_noise_0.1-03-14-24_11_53_08-91577252-aa44-4133-8ec7-a5fcda220d3a\"\n",
    "\n",
    "    # all_omniglot-pixel_noise_0.1\n",
    "    \"bursty_1.0-diff_pos_enc-03-19-24_11_07_54-6f37e06f-569d-427c-a14c-9c9d54587c5b\"\n",
    ")\n",
    "\n",
    "learner_path = os.path.join(\n",
    "    log_path,\n",
    "    project_name,\n",
    "    ablation_name,\n",
    "    run_name,\n",
    ")\n",
    "\n",
    "exp_name = \"-\".join(run_name.split(\"-\")[:-8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict, config = load_config(learner_path)\n",
    "fixed_length = config.learner_config.dataset_config.dataset_wrapper.type in [\"FixedLengthContextDataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(\n",
    "    config.learner_config.dataset_config,\n",
    "    config.learner_config.seeds.data_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, model = load_model(\n",
    "    train_dataset.input_dim, train_dataset.output_dim, learner_path, -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_tasks = 30\n",
    "test_data_seed = 1000\n",
    "\n",
    "context_len = config.model_config.num_contexts\n",
    "num_samples_per_task = train_dataset._dataset.sequence_length - 1\n",
    "sequence_length = train_dataset._dataset.sequence_length\n",
    "num_tasks = 100\n",
    "num_workers = 4\n",
    "\n",
    "print(num_samples_per_task, num_tasks, sequence_length, context_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dataset example\n",
    "def plot_examples(dataset, num_examples = 2):\n",
    "    num_samples_per_task = dataset._dataset.sequence_length - 1\n",
    "    for task_i in range(num_examples):\n",
    "        ci, co, q, l = dataset[\n",
    "            task_i * num_samples_per_task + num_samples_per_task - 1\n",
    "        ]\n",
    "\n",
    "        nrows = 2\n",
    "        ncols = 8\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows,\n",
    "            ncols + 1,\n",
    "            figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "            layout=\"constrained\",\n",
    "        )\n",
    "\n",
    "        for idx, (img, label) in enumerate(zip(ci, co)):\n",
    "            axes[idx // ncols, idx % ncols].imshow(img)\n",
    "            axes[idx // ncols, idx % ncols].set_title(np.argmax(label))\n",
    "            axes[idx // ncols, idx % ncols].axis('off')\n",
    "        axes[0, -1].axis('off')\n",
    "        axes[1, -1].axis('off')\n",
    "        axes[1, -1].imshow(q[0])\n",
    "        axes[1, -1].set_title(np.argmax(l, axis=-1))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# Get model predictions\n",
    "def get_preds_labels(data_loader, num_tasks, max_label=None):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "\n",
    "    for batch_i, samples in enumerate(data_loader):\n",
    "        if batch_i >= num_tasks:\n",
    "            break\n",
    "\n",
    "        (context_inputs, context_outputs, queries, one_hot_labels) = samples\n",
    "\n",
    "        outputs, _, _ = model.forward(\n",
    "            params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "            queries.numpy(),\n",
    "            {\n",
    "                CONST_CONTEXT_INPUT: context_inputs.numpy(),\n",
    "                CONST_CONTEXT_OUTPUT: context_outputs.numpy(),\n",
    "            },\n",
    "            eval=True,\n",
    "        )\n",
    "        # return train_outputs, train_updates, outputs, updates\n",
    "        if max_label is None:\n",
    "            preds = np.argmax(outputs, axis=-1)\n",
    "        elif max_label == CONST_AUTO:\n",
    "            preds = np.argmax(outputs[..., :data_loader.dataset._data[\"num_classes\"]], axis=-1)\n",
    "        else:\n",
    "            preds = np.argmax(outputs[..., :max_label], axis=-1)\n",
    "        labels = np.argmax(one_hot_labels, axis=-1)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "        all_outputs.append(outputs)\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_preds, all_labels, all_outputs\n",
    "\n",
    "# Check model accuracy\n",
    "def print_performance(\n",
    "    all_preds,\n",
    "    all_labels,\n",
    "    output_dim,\n",
    "):\n",
    "    result_str = \"\"\n",
    "    conf_mat = confusion_matrix(all_labels, all_preds, labels=np.arange(output_dim))\n",
    "    acc = np.trace(conf_mat) / np.sum(conf_mat) * 100\n",
    "    result_str += \"Accuracy: {}%\\n\".format(acc)\n",
    "\n",
    "    return result_str\n",
    "\n",
    "# Complete evaluation\n",
    "def evaluate(exp_name, eval_name, dataset_config, seed, num_tasks, max_label, batch_size, num_workers, visualize=False, save=False):\n",
    "    dataset = get_dataset(\n",
    "        dataset_config,\n",
    "        seed,\n",
    "    )\n",
    "\n",
    "    if visualize:\n",
    "        plot_examples(dataset)\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    preds, labels, outputs = get_preds_labels(data_loader, num_tasks, max_label)\n",
    "    acc_str = print_performance(\n",
    "        preds,\n",
    "        labels,\n",
    "        dataset.output_dim[0],\n",
    "    )\n",
    "\n",
    "    if save:\n",
    "        save_dir = \"./evaluation-{}\".format(exp_name)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pickle.dump(\n",
    "            {\n",
    "                \"config\": dataset_config,\n",
    "                \"seed\": seed,\n",
    "                \"max_label\": max_label,\n",
    "                \"num_tasks\": num_tasks,\n",
    "                \"results\": {\n",
    "                    \"preds\": preds,\n",
    "                    \"labels\": labels,\n",
    "                    \"outputs\": outputs,\n",
    "                    \"acc_str\": acc_str,\n",
    "                }\n",
    "            },\n",
    "            open(os.path.join(save_dir, \"{}.pkl\".format(eval_name)), \"wb\"),\n",
    "        )\n",
    "    return acc_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "Pretraining is the exact same dataset for training the ICL model---we expect the performance to be near perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_acc = evaluate(\n",
    "    exp_name=exp_name,\n",
    "    eval_name=\"pretraining\",\n",
    "    dataset_config=config.learner_config.dataset_config,\n",
    "    seed=config.learner_config.seeds.data_seed,\n",
    "    num_tasks=num_tasks,\n",
    "    max_label=None,\n",
    "    batch_size=num_samples_per_task,\n",
    "    num_workers=num_workers,\n",
    "    save=True,\n",
    "    visualize=True,\n",
    ")\n",
    "print(pretrain_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-distribution Evaluation\n",
    "This uses the pretraining image classes.  \n",
    "We consider three types of evaluations:\n",
    "1. **Same pretraining data distribution accuracy**: This uses the same dataset as the pretraining but with a different seed.  \n",
    "This may change, for example, the augmentation or the sequences.\n",
    "\n",
    "1. **In-weight accuracy**: This uses totally random contexts and the model should predict purely using the query.  \n",
    "This follows from Chan et al. (2022).  \n",
    "Note: When $P(\\text{bursty}) = 0$ for pretraining, then this is the same as same pretraining data distribution\n",
    "\n",
    "1. **Pretraining N-shot 2-way accuracy**: This uses the same dataset as the pretraining but with a different seed  \n",
    "Furthermore, we relabel each task to be a binary classification task such that half of the contexts are filled with class 1, and half with class 0.  \n",
    "We constrain the model output to only be the valid classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Pretraining Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_pretraining_config_dict = copy.deepcopy(\n",
    "    config_dict[\"learner_config\"][\"dataset_config\"]\n",
    ")\n",
    "same_pretraining_config_dict[\"dataset_kwargs\"][\"num_sequences\"] = num_test_tasks\n",
    "same_pretraining_config = parse_dict(same_pretraining_config_dict)\n",
    "\n",
    "same_pretraining_acc = evaluate(\n",
    "    exp_name=exp_name,\n",
    "    eval_name=\"same_pretraining\",\n",
    "    dataset_config=same_pretraining_config,\n",
    "    seed=test_data_seed,\n",
    "    num_tasks=num_test_tasks,\n",
    "    max_label=None,\n",
    "    batch_size=num_samples_per_task,\n",
    "    num_workers=num_workers,\n",
    "    save=True,\n",
    "    visualize=True,\n",
    ")\n",
    "print(same_pretraining_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_weight_config_dict = copy.deepcopy(\n",
    "    config_dict[\"learner_config\"][\"dataset_config\"]\n",
    ")\n",
    "in_weight_config_dict[\"dataset_kwargs\"][\"num_sequences\"] = num_test_tasks\n",
    "in_weight_config_dict[\"dataset_kwargs\"][\"task_config\"][\"p_bursty\"] = 0.0\n",
    "in_weight_config_dict[\"dataset_kwargs\"][\"task_config\"][\"unique_classes\"] = True\n",
    "in_weight_config = parse_dict(in_weight_config_dict)\n",
    "\n",
    "in_weight_acc = evaluate(\n",
    "    exp_name=exp_name,\n",
    "    eval_name=\"in_weight\",\n",
    "    dataset_config=in_weight_config,\n",
    "    seed=test_data_seed,\n",
    "    num_tasks=num_test_tasks,\n",
    "    max_label=None,\n",
    "    batch_size=num_samples_per_task,\n",
    "    num_workers=num_workers,\n",
    "    save=True,\n",
    "    visualize=True,\n",
    ")\n",
    "print(in_weight_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining N-shot 2-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_n_shot_2_way_config_dict = copy.deepcopy(config_dict[\"learner_config\"][\"dataset_config\"])\n",
    "pretrain_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"task_name\"] = CONST_MULTITASK_OMNIGLOT_N_SHOT_K_WAY\n",
    "pretrain_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"task_config\"][\"p_bursty\"] = 1.0\n",
    "pretrain_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"task_config\"][\"k_way\"] = 2\n",
    "pretrain_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"num_sequences\"] = num_test_tasks\n",
    "pretrain_n_shot_2_way_config = parse_dict(pretrain_n_shot_2_way_config_dict)\n",
    "\n",
    "pretrain_n_shot_2_way_acc = evaluate(\n",
    "    exp_name=exp_name,\n",
    "    eval_name=\"pretrain_n_shot_2_way\",\n",
    "    dataset_config=pretrain_n_shot_2_way_config,\n",
    "    seed=test_data_seed,\n",
    "    num_tasks=num_test_tasks,\n",
    "    max_label=2,\n",
    "    batch_size=num_samples_per_task,\n",
    "    num_workers=num_workers,\n",
    "    save=True,\n",
    "    visualize=True,\n",
    ")\n",
    "print(pretrain_n_shot_2_way_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-context Evaluation\n",
    "This uses heldout image classes.  \n",
    "We consider two types of evaluations:\n",
    "1. **Complete out-of-distribution accuracy**: We use simply the heldout classes.  \n",
    "We constrain the model output to only be the valid classes.\n",
    "\n",
    "1. **N-shot 2-way accuracy**: We treat each task to be a binary classification task such that half of the contexts are filled with class 1, and half with class 0.  \n",
    "We constrain the model output to only be the valid classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Out-of-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_config_dict = copy.deepcopy(\n",
    "    config_dict[\"learner_config\"][\"dataset_config\"]\n",
    ")\n",
    "ood_config_dict[\"dataset_kwargs\"][\"train\"] = False\n",
    "ood_config_dict[\"dataset_kwargs\"][\"num_sequences\"] = num_test_tasks\n",
    "ood_config = parse_dict(ood_config_dict)\n",
    "\n",
    "ood_acc = evaluate(\n",
    "    exp_name=exp_name,\n",
    "    eval_name=\"ood\",\n",
    "    dataset_config=ood_config,\n",
    "    seed=test_data_seed,\n",
    "    num_tasks=num_test_tasks,\n",
    "    max_label=CONST_AUTO,\n",
    "    batch_size=num_samples_per_task,\n",
    "    num_workers=num_workers,\n",
    "    save=True,\n",
    ")\n",
    "print(ood_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-shot 2-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_shot_2_way_config_dict = copy.deepcopy(config_dict[\"learner_config\"][\"dataset_config\"])\n",
    "test_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"train\"] = False\n",
    "test_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"task_name\"] = CONST_MULTITASK_OMNIGLOT_N_SHOT_K_WAY\n",
    "test_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"task_config\"][\"p_bursty\"] = 1.0\n",
    "test_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"task_config\"][\"k_way\"] = 2\n",
    "test_n_shot_2_way_config_dict[\"dataset_kwargs\"][\"num_sequences\"] = num_test_tasks\n",
    "test_n_shot_2_way_config = parse_dict(test_n_shot_2_way_config_dict)\n",
    "\n",
    "test_n_shot_2_way_acc = evaluate(\n",
    "    exp_name=exp_name,\n",
    "    eval_name=\"test_n_shot_2_way\",\n",
    "    dataset_config=test_n_shot_2_way_config,\n",
    "    seed=test_data_seed,\n",
    "    num_tasks=num_test_tasks,\n",
    "    max_label=2,\n",
    "    batch_size=num_samples_per_task,\n",
    "    num_workers=num_workers,\n",
    "    save=True,\n",
    ")\n",
    "print(test_n_shot_2_way_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accs = OrderedDict(\n",
    "    pretraining=pretrain_acc,\n",
    "    same_pretraining=same_pretraining_acc,\n",
    "    in_weight=in_weight_acc,\n",
    "    pretrain_n_shot_2_way=pretrain_n_shot_2_way_acc,\n",
    "    ood=ood_acc,\n",
    "    test_n_shot_2_way=test_n_shot_2_way_acc,\n",
    ")\n",
    "\n",
    "all_accs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
