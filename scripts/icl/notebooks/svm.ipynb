{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets import get_dataset\n",
    "from jaxl.learning_utils import get_learner\n",
    "from jaxl.plot_utils import set_size\n",
    "from jaxl.utils import parse_dict\n",
    "\n",
    "import copy\n",
    "import cvxpy as cp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "import os\n",
    "\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/Users/chanb/research/personal/jaxl/configs/icl/gpt-linear_classification-query_pred_only.json\"\n",
    "seed = 0\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "    config = parse_dict(config_dict)\n",
    "\n",
    "dataset = get_dataset(config.learner_config.dataset_config, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, one_hot_y, test_x, test_y = dataset[10]\n",
    "train_y = np.argmax(one_hot_y, axis=-1)\n",
    "train_y[train_y == 0] = -1\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def make_svm(inputs, outputs, reg_coef):\n",
    "    svm = make_pipeline(\n",
    "        LinearSVC(C=reg_coef, max_iter=2000, loss=\"hinge\", fit_intercept=True),\n",
    "    )\n",
    "    svm.fit(inputs, np.argmax(outputs, axis=1))\n",
    "    return svm\n",
    "\n",
    "\n",
    "svm = make_svm(train_x, one_hot_y, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SolveQP\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_x & \\frac{1}{2} x^\\top P x + q^\\top x \\\\\n",
    "    \\text{s.t. } & Gx \\leq h\\\\\n",
    "    & Ax = b\\\\\n",
    "    & lb \\leq x \\leq ub\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Example usage:\n",
    "```\n",
    "# Import packages.\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random non-trivial quadratic program.\n",
    "m = 15\n",
    "n = 10\n",
    "p = 5\n",
    "np.random.seed(1)\n",
    "P = np.random.randn(n, n)\n",
    "P = P.T @ P\n",
    "q = np.random.randn(n)\n",
    "G = np.random.randn(m, n)\n",
    "h = G @ np.random.randn(n)\n",
    "A = np.random.randn(p, n)\n",
    "b = np.random.randn(p)\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(n)\n",
    "prob = cp.Problem(cp.Minimize((1/2)*cp.quad_form(x, P) + q.T @ x),\n",
    "                 [G @ x <= h,\n",
    "                  A @ x == b])\n",
    "prob.solve()\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"A solution x is\")\n",
    "print(x.value)\n",
    "print(\"A dual solution corresponding to the inequality constraints is\")\n",
    "print(prob.constraints[0].dual_value)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primal SVM\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{w, b} & \\frac{1}{2} w^\\top w \\\\\n",
    "    \\text{s.t. } & (w^\\top x_j + b) y_j \\geq 1, \\forall j \\in [N]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_x = np.concatenate((train_x, np.ones((8, 1))), axis=-1)\n",
    "P = np.eye(3)\n",
    "P[2] = 0\n",
    "q = np.zeros(3)\n",
    "G = padded_x * -train_y[:, None]\n",
    "h = -np.ones(8)\n",
    "\n",
    "primal_var = cp.Variable(3)\n",
    "prob = cp.Problem(\n",
    "    cp.Minimize((1 / 2) * cp.quad_form(primal_var, P) + q.T @ primal_var),\n",
    "    [G @ primal_var <= h],\n",
    ")\n",
    "print(prob.solve())\n",
    "params = primal_var.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For given parameters, we can optimize for the dual parameters:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\alpha} & \\frac{1}{2} \\lVert w \\rVert^2 - \\sum_{i}^N \\alpha_i y_i (x_i \\cdot w + b) + \\alpha_i \\\\\n",
    "    \\text{s.t. } & \\alpha_i \\geq 0\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual SVM\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\max_{\\alpha} & \\sum_{i}^N \\alpha_i - \\frac{1}{2} \\sum_{i, j} \\alpha_i \\alpha_j y_i y_j (x_i \\cdot x_j) \\\\\n",
    "    \\text{s.t. } & \\sum_{i} \\alpha_i y_i = 0\\\\\n",
    "    & \\alpha_i \\geq 0\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel\n",
    "K = train_x @ train_x.T\n",
    "P = (train_y[:, None] @ train_y[None]) * K\n",
    "q = -np.ones(len(train_x))\n",
    "A = train_y[None]\n",
    "b = np.zeros(1)\n",
    "G = -np.eye(len(train_x))\n",
    "h = np.zeros(len(train_x))\n",
    "\n",
    "dual_var = cp.Variable(len(train_x))\n",
    "prob = cp.Problem(\n",
    "    cp.Minimize((1 / 2) * cp.quad_form(dual_var, P) + q.T @ dual_var),\n",
    "    [G @ dual_var <= h, A @ dual_var == b],\n",
    ")\n",
    "print(prob.solve())\n",
    "alphas = dual_var.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params, svm[0].coef_, np.sum((alphas * train_y)[:, None] * train_x, axis=0))\n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = svm.decision_function(train_x)\n",
    "support_vector_indices = np.where(np.abs(decision_function) <= 1)[0]\n",
    "print(support_vector_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [-1, 1]:\n",
    "    idxes = train_y == label\n",
    "    plt.scatter(train_x[idxes][:, 0], train_x[idxes][:, 1], label=label)\n",
    "plt.legend()\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
