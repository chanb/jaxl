{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import jax\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from jaxl.constants import *\n",
    "from jaxl.plot_utils import set_size\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_width_pt = 750.0\n",
    "# baseline_path = \"/home/bryanpu1/projects/jaxl/scripts/icl/results-num_blocks_8-num_tasks_5-seq_len_16-seed_9999-10-11-23_20_07_56\"\n",
    "# baseline_path = \"/home/bryanpu1/projects/jaxl/scripts/icl/results-num_blocks_8-seq_len_20-num_tasks_5-seq_len_20-seed_9999-10-13-23_10_30_57/\"\n",
    "baseline_path = \"/home/bryanpu1/projects/jaxl/scripts/icl/results-num_blocks_8-smaller_delta-num_tasks_5-seq_len_20-seed_9999-10-17-23_22_07_47\"\n",
    "\n",
    "context_data = pickle.load(\n",
    "    open(os.path.join(baseline_path, \"context_data.pkl\"), \"rb\")\n",
    ")\n",
    "\n",
    "gt = pickle.load(\n",
    "    open(os.path.join(baseline_path, \"ground_truth.pkl\"), \"rb\")\n",
    ")\n",
    "\n",
    "agent_reprs = pickle.load(\n",
    "    open(os.path.join(baseline_path, \"agent_reprs.pkl\"), \"rb\")\n",
    ")\n",
    "\n",
    "agent_results = pickle.load(\n",
    "    open(os.path.join(baseline_path, \"agents.pkl\"), \"rb\")\n",
    ")\n",
    "\n",
    "config = pickle.load(\n",
    "    open(os.path.join(baseline_path, \"config.pkl\"), \"rb\")\n",
    ")\n",
    "\n",
    "baseline_results = pickle.load(\n",
    "    open(os.path.join(baseline_path, \"baseline_results.pkl\"), \"rb\")\n",
    ")\n",
    "\n",
    "input_range = config[\"input_range\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize ICL Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "for task_i in context_data:\n",
    "    context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "    context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]\n",
    "    train_y = np.argmax(context_outputs, axis=-1)\n",
    "\n",
    "    for agent_path, agent_result in agent_results.items():\n",
    "        print(\"Processing agent {}\".format(agent_path))\n",
    "\n",
    "        svm_primal = agent_reprs[agent_path][\"svms\"][task_i][\"input\"][\"primal\"][\"sol\"]\n",
    "        svm_db = -(np.array(input_range) * svm_primal[0] + svm_primal[2]) / svm_primal[1]\n",
    "\n",
    "        primal_out = (context_inputs @ svm_primal[:-1]) + svm_primal[-1]\n",
    "        primal_constraints = 2 * (0.5 - (1 - train_y)) * primal_out\n",
    "        print(primal_constraints)\n",
    "        support_vectors = context_inputs[np.where(primal_constraints <= 1 + 1e-5)[0]]\n",
    "\n",
    "        poss = np.where(primal_out > 0)[0]\n",
    "        negs = np.where(primal_out < 0)[0]\n",
    "        closest_pos = context_inputs[poss[np.argmin(primal_out[poss])]]\n",
    "        closest_neg = context_inputs[negs[np.argmax(primal_out[negs])]]\n",
    "\n",
    "        per_task_results = agent_result[task_i]\n",
    "        nrows = math.ceil(len(per_task_results[\"examplar_length\"]) / ncols)\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows,\n",
    "            ncols,\n",
    "            figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "            layout=\"constrained\",\n",
    "        )\n",
    "        \n",
    "        for ax_i, examplar_len in enumerate(per_task_results[\"examplar_length\"]):\n",
    "            mask = (np.arange(len(context_inputs)) >= len(context_inputs) - examplar_len)\n",
    "            if nrows == 1:\n",
    "                ax = axes[ax_i]\n",
    "            else:\n",
    "                ax = axes[ax_i // ncols, ax_i % ncols]\n",
    "            one_hot_preds = per_task_results[\"examplar_length\"][examplar_len]\n",
    "            preds = np.argmax(one_hot_preds, axis=-1)\n",
    "            \n",
    "            for possible_label in [0, 1]:\n",
    "                idxes = np.where(preds == possible_label)\n",
    "                ax.scatter(\n",
    "                    gt[\"inputs\"][idxes][:, 0],\n",
    "                    gt[\"inputs\"][idxes][:, 1],\n",
    "                    label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "                    s=5,\n",
    "                    alpha=0.1,\n",
    "                )\n",
    "                idxes = np.where(train_y[mask] == possible_label)\n",
    "                ax.scatter(\n",
    "                    context_inputs[mask][idxes][:, 0],\n",
    "                    context_inputs[mask][idxes][:, 1],\n",
    "                    label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "                    s=15,\n",
    "                    marker=\"x\" if possible_label else \"o\",\n",
    "                    c=\"black\"\n",
    "                )\n",
    "\n",
    "            ax.scatter(\n",
    "                support_vectors[:, 0],\n",
    "                support_vectors[:, 1],\n",
    "                label=f\"support vector\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=\"black\",\n",
    "            )\n",
    "\n",
    "            ax.scatter(\n",
    "                closest_pos[0],\n",
    "                closest_pos[1],\n",
    "                label=f\"closest +\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                marker=\"^\"\n",
    "            )\n",
    "\n",
    "            ax.scatter(\n",
    "                closest_neg[0],\n",
    "                closest_neg[1],\n",
    "                label=f\"closest -\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                marker=\"^\"\n",
    "            )\n",
    "            \n",
    "            ax.plot(\n",
    "                input_range,\n",
    "                gt[\"decision_boundary\"][task_i],\n",
    "                color=\"gray\",\n",
    "                label=\"gt\" if ax_i == 0 else \"\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                input_range,\n",
    "                svm_db,\n",
    "                color=\"black\",\n",
    "                label=\"svm\" if ax_i == 0 else \"\"\n",
    "            )\n",
    "            ax.set_xlim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "            ax.set_ylim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "            ax.set_title(\"Ex. Len.: {}\".format(examplar_len))\n",
    "            ax.grid(False)\n",
    "\n",
    "        fig.legend(\n",
    "            bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "            loc=\"lower center\",\n",
    "            ncols=10,\n",
    "            borderaxespad=0.0,\n",
    "            frameon=True,\n",
    "            fontsize=\"8\",\n",
    "        )\n",
    "        fig.supxlabel(\"$x_1$\")\n",
    "        fig.supylabel(\"$x_2$\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Representation SVM\n",
    "Visualize SVM trained in the represnetation space induced by the transformer by mapping the SVM prediction back onto the input space.\n",
    "- `context_reprs` corresponds to the representation induced by feeding in each of the context samples into the query token\n",
    "- `input_token_context_reprs` corresponds to taking the context token directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "for task_i in context_data:\n",
    "    context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "    context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]\n",
    "    train_y = np.argmax(context_outputs, axis=-1)\n",
    "\n",
    "    for agent_path, agent_repr in agent_reprs.items():\n",
    "        print(\"Processing agent {}\".format(agent_path))\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows,\n",
    "            ncols,\n",
    "            figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "            layout=\"constrained\",\n",
    "        )\n",
    "        query_input = agent_repr[\"query_reprs\"][task_i]\n",
    "        for ax_i, repr_key in enumerate([\"query_context_reprs\", \"input_context_reprs\"]):\n",
    "\n",
    "            svm_primal = agent_repr[\"svms\"][task_i][repr_key][\"primal\"][\"sol\"]\n",
    "            svm_db = -(np.array(input_range) * svm_primal[0] + svm_primal[2]) / svm_primal[1]\n",
    "\n",
    "            primal_out = (np.array(agent_repr[repr_key][task_i]) @ svm_primal[:-1]) + svm_primal[-1]\n",
    "            primal_constraints = 2 * (0.5 - (1 - train_y)) * primal_out\n",
    "            print(primal_out)\n",
    "            support_vectors = context_inputs[np.where(primal_constraints <= 1 + 1e-5)[0]]\n",
    "            \n",
    "            poss = np.where(primal_out > 0)[0]\n",
    "            negs = np.where(primal_out < 0)[0]\n",
    "            closest_pos_dist = np.min(primal_out[poss])\n",
    "            closest_neg_dist = np.max(primal_out[negs])\n",
    "            closest_pos = context_inputs[np.isclose(closest_pos_dist, primal_out, atol=0.1)]\n",
    "            closest_neg = context_inputs[np.isclose(closest_neg_dist, primal_out, atol=0.1)]\n",
    "            \n",
    "            ax = axes[ax_i]\n",
    "            svm_preds = (\n",
    "                (\n",
    "                    np.array(query_input) @ svm_primal[:-1]\n",
    "                    + svm_primal[-1:]\n",
    "                )\n",
    "                >= 0\n",
    "            ).astype(int)\n",
    "            \n",
    "            for possible_label in [0, 1]:\n",
    "                idxes = np.where(svm_preds == possible_label)\n",
    "                ax.scatter(\n",
    "                    gt[\"inputs\"][idxes][:, 0],\n",
    "                    gt[\"inputs\"][idxes][:, 1],\n",
    "                    label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "                    s=5,\n",
    "                    alpha=0.1\n",
    "                )\n",
    "            for possible_label in [0, 1]:\n",
    "                idxes = np.where(train_y == possible_label)\n",
    "                ax.scatter(\n",
    "                    context_inputs[idxes][:, 0],\n",
    "                    context_inputs[idxes][:, 1],\n",
    "                    label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "                    s=15,\n",
    "                    marker=\"x\" if possible_label else \"o\",\n",
    "                    c=\"black\"\n",
    "                )\n",
    "\n",
    "            ax.scatter(\n",
    "                support_vectors[:, 0],\n",
    "                support_vectors[:, 1],\n",
    "                label=f\"support vector\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=\"black\",\n",
    "            )\n",
    "\n",
    "            ax.scatter(\n",
    "                closest_pos[:, 0],\n",
    "                closest_pos[:, 1],\n",
    "                label=f\"closest +\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                marker=\"^\"\n",
    "            )\n",
    "\n",
    "            ax.scatter(\n",
    "                closest_neg[:, 0],\n",
    "                closest_neg[:, 1],\n",
    "                label=f\"closest -\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                marker=\"^\"\n",
    "            )\n",
    "            \n",
    "            ax.plot(\n",
    "                input_range,\n",
    "                gt[\"decision_boundary\"][task_i],\n",
    "                color=\"gray\",\n",
    "                label=\"gt\" if ax_i == 0 else \"\"\n",
    "            )\n",
    "\n",
    "            ax.set_xlim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "            ax.set_ylim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "            ax.set_title(\"{}\".format(repr_key))\n",
    "            ax.grid(False)\n",
    "\n",
    "        fig.legend(\n",
    "            bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "            loc=\"lower center\",\n",
    "            ncols=4,\n",
    "            borderaxespad=0.0,\n",
    "            frameon=True,\n",
    "            fontsize=\"8\",\n",
    "        )\n",
    "        fig.supxlabel(\"$x_1$\")\n",
    "        fig.supylabel(\"$x_2$\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Support Vector from Transformer Embedding\n",
    "Current observation:\n",
    "- There does not seem to be gap in the classification, yet the context samples are classified incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 3\n",
    "for task_i in context_data:\n",
    "    context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "    context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]\n",
    "    train_y = np.argmax(context_outputs, axis=-1)\n",
    "\n",
    "    for agent_path, agent_repr in agent_reprs.items():\n",
    "        print(\"Processing agent {}\".format(agent_path))\n",
    "        svm_primal = agent_reprs[agent_path][\"svms\"][task_i][\"input\"][\"primal\"][\"sol\"]\n",
    "        svm_db = -(np.array(input_range) * svm_primal[0] + svm_primal[2]) / svm_primal[1]\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows,\n",
    "            ncols,\n",
    "            figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "            layout=\"constrained\",\n",
    "        )\n",
    "        \n",
    "        per_task_results = agent_results[agent_path][task_i]\n",
    "        one_hot_preds = per_task_results[\"examplar_length\"][np.max(list(per_task_results[\"examplar_length\"].keys()))]\n",
    "        preds = np.argmax(one_hot_preds, axis=-1)\n",
    "        \n",
    "        sqrt_num_samples = int(math.sqrt(len(preds)))\n",
    "        axes[2].imshow(preds.reshape((sqrt_num_samples, sqrt_num_samples))[::-1])\n",
    "        axes[2].set_title(\"Transformer Decision Boundary\")\n",
    "\n",
    "        query_input = agent_repr[\"query_reprs\"][task_i]\n",
    "        for ax_i, repr_key in enumerate([\"query_context_reprs\", \"input_context_reprs\"]):\n",
    "\n",
    "            embed_first_dim = np.array(agent_reprs[agent_path][repr_key][task_i])[:, 0]\n",
    "            \n",
    "            poss = np.where(embed_first_dim > 0)[0]\n",
    "            negs = np.where(embed_first_dim < 0)[0]\n",
    "            closest_pos_dist = np.min(embed_first_dim[poss])\n",
    "            closest_neg_dist = np.max(embed_first_dim[negs])\n",
    "            closest_pos = context_inputs[np.isclose(closest_pos_dist, embed_first_dim, atol=0.1)]\n",
    "            closest_neg = context_inputs[np.isclose(closest_neg_dist, embed_first_dim, atol=0.1)]\n",
    "            \n",
    "            ax = axes[ax_i]\n",
    "            \n",
    "            for possible_label in [0, 1]:\n",
    "                idxes = np.where(preds == possible_label)\n",
    "                ax.scatter(\n",
    "                    gt[\"inputs\"][idxes][:, 0],\n",
    "                    gt[\"inputs\"][idxes][:, 1],\n",
    "                    label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "                    s=5,\n",
    "                    alpha=0.1\n",
    "                )\n",
    "            for possible_label in [0, 1]:\n",
    "                idxes = np.where(train_y == possible_label)\n",
    "                ax.scatter(\n",
    "                    context_inputs[idxes][:, 0],\n",
    "                    context_inputs[idxes][:, 1],\n",
    "                    label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "                    s=15,\n",
    "                    marker=\"x\" if possible_label else \"o\",\n",
    "                    c=\"black\"\n",
    "                )\n",
    "\n",
    "            ax.scatter(\n",
    "                closest_pos[:, 0],\n",
    "                closest_pos[:, 1],\n",
    "                label=f\"closest +\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=\"red\",\n",
    "            )\n",
    "\n",
    "            ax.scatter(\n",
    "                closest_neg[:, 0],\n",
    "                closest_neg[:, 1],\n",
    "                label=f\"closest -\" if ax_i == 0 else \"\",\n",
    "                s=70,\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=\"blue\",\n",
    "            )\n",
    "            \n",
    "            ax.plot(\n",
    "                input_range,\n",
    "                svm_db,\n",
    "                color=\"black\",\n",
    "                label=\"svm\" if ax_i == 0 else \"\"\n",
    "            )\n",
    "\n",
    "            ax.set_xlim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "            ax.set_ylim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "            ax.set_title(\"{}\".format(repr_key))\n",
    "            ax.grid(False)\n",
    "\n",
    "        fig.legend(\n",
    "            bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "            loc=\"lower center\",\n",
    "            ncols=4,\n",
    "            borderaxespad=0.0,\n",
    "            frameon=True,\n",
    "            fontsize=\"8\",\n",
    "        )\n",
    "        fig.supxlabel(\"$x_1$\")\n",
    "        fig.supylabel(\"$x_2$\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Experiment\n",
    "- Permute -> embed\n",
    "- Embed -> permute\n",
    "\n",
    "Expectation: If the transformer end up being permutation invariant, then the first dimension of the representation space should be the same under the permutation of two operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 3\n",
    "for task_i in context_data:\n",
    "    context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "    context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]\n",
    "    train_y = np.argmax(context_outputs, axis=-1)\n",
    "\n",
    "    for agent_path, agent_repr in agent_reprs.items():\n",
    "        print(\"Processing agent {}\".format(agent_path))\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows,\n",
    "            ncols,\n",
    "            figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "            layout=\"constrained\",\n",
    "        )\n",
    "        \n",
    "        per_task_results = agent_results[agent_path][task_i]\n",
    "        one_hot_preds = per_task_results[\"examplar_length\"][np.max(list(per_task_results[\"examplar_length\"].keys()))]\n",
    "        preds = np.argmax(one_hot_preds, axis=-1)\n",
    "\n",
    "        query_input = agent_repr[\"query_reprs\"][task_i]\n",
    "        for ax_i, repr_key in enumerate([\"query_context_reprs\", \"input_context_reprs\"]):\n",
    "\n",
    "            ax = axes[ax_i, 2]\n",
    "            permute_idxes = np.array(agent_reprs[agent_path][\"permutation\"][repr_key][task_i][\"permute_idxes\"])\n",
    "            ax.plot(\n",
    "                [0, 1],\n",
    "                [0, 1],\n",
    "                transform=ax.transAxes,\n",
    "                linestyle=\"--\",\n",
    "                color=\"black\",\n",
    "            )\n",
    "            ax.scatter(\n",
    "                np.array(agent_reprs[agent_path][repr_key][task_i])[:, 0],\n",
    "                np.array(agent_reprs[agent_path][\"permutation\"][repr_key][task_i][\"repr\"])[:, 0],\n",
    "                marker=\"x\",\n",
    "                color=[\"red\" if idx < len(context_inputs) // 2 else \"blue\" for idx in range(len(context_inputs))]\n",
    "            )\n",
    "            print(np.concatenate((\n",
    "                np.array(agent_reprs[agent_path][repr_key][task_i])[:, [0]],\n",
    "                np.array(agent_reprs[agent_path][\"permutation\"][repr_key][task_i][\"repr\"])[:, [0]],\n",
    "                permute_idxes[:, None]\n",
    "            ), axis=-1))\n",
    "            ax.set_xlabel(\"Embed then permute\")\n",
    "            ax.set_ylabel(\"Permute then embed\")\n",
    "            ax.set_title(\"distance based on first dim\")\n",
    "\n",
    "            for ii, is_permute in enumerate((False, True)):\n",
    "                if is_permute:\n",
    "                    embed_first_dim = np.array(agent_reprs[agent_path][\"permutation\"][repr_key][task_i][\"repr\"])[:, 0]\n",
    "                else:\n",
    "                    embed_first_dim = np.array(agent_reprs[agent_path][repr_key][task_i])[:, 0]\n",
    "                \n",
    "                poss = np.where(embed_first_dim > 0)[0]\n",
    "                negs = np.where(embed_first_dim < 0)[0]\n",
    "                closest_pos_dist = np.min(embed_first_dim[poss])\n",
    "                closest_neg_dist = np.max(embed_first_dim[negs])\n",
    "                closest_pos = context_inputs[np.isclose(closest_pos_dist, embed_first_dim, atol=0.1)]\n",
    "                closest_neg = context_inputs[np.isclose(closest_neg_dist, embed_first_dim, atol=0.1)]\n",
    "                \n",
    "                ax = axes[ax_i, ii]\n",
    "\n",
    "                print(\"{} - Permutation {} - In-context Prediction Accuracy: {}%\".format(\n",
    "                    repr_key,\n",
    "                    is_permute,\n",
    "                    np.mean((jax.nn.sigmoid(embed_first_dim) >= 0.5) == train_y) * 100\n",
    "                ))\n",
    "                \n",
    "                for possible_label in [0, 1]:\n",
    "                    idxes = np.where(preds == possible_label)\n",
    "                    ax.scatter(\n",
    "                        gt[\"inputs\"][idxes][:, 0],\n",
    "                        gt[\"inputs\"][idxes][:, 1],\n",
    "                        label=f\"{possible_label}\" if ax_i + ii == 0 else \"\",\n",
    "                        s=5,\n",
    "                        alpha=0.1\n",
    "                    )\n",
    "                for possible_label in [0, 1]:\n",
    "                    idxes = np.where(train_y == possible_label)\n",
    "                    ax.scatter(\n",
    "                        context_inputs[idxes][:, 0],\n",
    "                        context_inputs[idxes][:, 1],\n",
    "                        label=f\"{possible_label}\" if ax_i + ii == 0 else \"\",\n",
    "                        s=15,\n",
    "                        marker=\"x\" if possible_label else \"o\",\n",
    "                        c=\"black\"\n",
    "                    )\n",
    "\n",
    "                ax.scatter(\n",
    "                    closest_pos[:, 0],\n",
    "                    closest_pos[:, 1],\n",
    "                    label=f\"closest +\" if ax_i + ii == 0 else \"\",\n",
    "                    s=70,\n",
    "                    facecolors=\"none\",\n",
    "                    edgecolors=\"red\",\n",
    "                )\n",
    "\n",
    "                ax.scatter(\n",
    "                    closest_neg[:, 0],\n",
    "                    closest_neg[:, 1],\n",
    "                    label=f\"closest -\" if ax_i + ii == 0 else \"\",\n",
    "                    s=70,\n",
    "                    facecolors=\"none\",\n",
    "                    edgecolors=\"blue\",\n",
    "                )\n",
    "                \n",
    "                ax.plot(\n",
    "                    input_range,\n",
    "                    gt[\"decision_boundary\"][task_i],\n",
    "                    color=\"gray\",\n",
    "                    label=\"gt\" if ax_i + ii == 0 else \"\"\n",
    "                )\n",
    "\n",
    "                ax.set_xlim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "                ax.set_ylim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "                ax.set_title(\"{}{}\".format(repr_key, \" permuted\" if is_permute else \"\"))\n",
    "                ax.grid(False)\n",
    "\n",
    "        fig.legend(\n",
    "            bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "            loc=\"lower center\",\n",
    "            ncols=4,\n",
    "            borderaxespad=0.0,\n",
    "            frameon=True,\n",
    "            fontsize=\"8\",\n",
    "        )\n",
    "        fig.supxlabel(\"$x_1$\")\n",
    "        fig.supylabel(\"$x_2$\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.learning_utils import get_learner\n",
    "from jaxl.utils import parse_dict\n",
    "\n",
    "import json\n",
    "\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "\n",
    "\n",
    "def load_llm(learner_path: str):\n",
    "    config_path = os.path.join(learner_path, \"config.json\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "        config = parse_dict(config_dict)\n",
    "\n",
    "    learner = get_learner(\n",
    "        config.learner_config, config.model_config, config.optimizer_config\n",
    "    )\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        os.path.join(learner_path, \"models\"),\n",
    "        PyTreeCheckpointer(),\n",
    "    )\n",
    "\n",
    "    llm_params = checkpoint_manager.restore(checkpoint_manager.latest_step())\n",
    "    llm_params[CONST_MODEL_DICT][CONST_MODEL][CONST_POSITIONAL_ENCODING] = dict()\n",
    "    llm_model = learner._model\n",
    "    return llm_params, llm_model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_model = load_llm(list(agent_results.keys())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chex\n",
    "\n",
    "from flax import linen as nn\n",
    "from typing import Tuple\n",
    "\n",
    "class GPTBlockWithInspection(nn.Module):\n",
    "    # : The number of attention heads\n",
    "    num_heads: int\n",
    "\n",
    "    # : The embedding dimensionality\n",
    "    embed_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: chex.Array) -> Tuple[chex.Array, chex.Array]:\n",
    "        mask = nn.make_causal_mask(x[..., 0])\n",
    "        attention = nn.SelfAttention(self.num_heads)(nn.LayerNorm()(x), mask)\n",
    "        x = x + attention\n",
    "        normed_x = nn.gelu(nn.Dense(self.embed_dim)(nn.LayerNorm()(x)))\n",
    "        x = x + nn.Dense(self.embed_dim)(normed_x)\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection = GPTBlockWithInspection(1, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Representation SVM at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate intermediate representations for the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(llm_params, llm_model, _) = agent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_i = 2\n",
    "context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, _ = jax.vmap(llm_model.tokenize, in_axes=[None, 0, None])(\n",
    "    llm_params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "    gt[\"inputs\"][:, None, None],\n",
    "    {\n",
    "        CONST_CONTEXT_INPUT: context_inputs[None],\n",
    "        CONST_CONTEXT_OUTPUT: context_outputs[None],\n",
    "    },\n",
    ")\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input_reprs = [tokens[:, 0, -1]]\n",
    "\n",
    "for layer_name in agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"]:\n",
    "    print(layer_name)\n",
    "    if layer_name.startswith(\"GPTBlock\"):\n",
    "        tokens, _ = inspection.apply(\n",
    "            {\"params\": agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"][layer_name]},\n",
    "            tokens\n",
    "        )\n",
    "    elif layer_name.startswith(\"LayerNorm\"):\n",
    "        tokens = nn.LayerNorm().apply(\n",
    "            {\"params\": agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"][layer_name]},\n",
    "            tokens\n",
    "        )\n",
    "    context_input_reprs.append(tokens[:, 0, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate intermediate representations for the contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, _ = jax.vmap(llm_model.tokenize, in_axes=[None, 0, None])(\n",
    "    llm_params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "    context_inputs[:, None, None],\n",
    "    {\n",
    "        CONST_CONTEXT_INPUT: context_inputs[None],\n",
    "        CONST_CONTEXT_OUTPUT: context_outputs[None],\n",
    "    },\n",
    ")\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_int_reprs = [tokens[0, 0, :-1:2]]\n",
    "query_int_reprs = [tokens[:, 0, -1]]\n",
    "\n",
    "for layer_name in agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"]:\n",
    "    print(layer_name)\n",
    "    if layer_name.startswith(\"GPTBlock\"):\n",
    "        tokens, _ = inspection.apply(\n",
    "            {\"params\": agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"][layer_name]},\n",
    "            tokens\n",
    "        )\n",
    "    elif layer_name.startswith(\"LayerNorm\"):\n",
    "        tokens = nn.LayerNorm().apply(\n",
    "            {\"params\": agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"][layer_name]},\n",
    "            tokens\n",
    "        )\n",
    "    print(tokens.shape)\n",
    "    input_int_reprs.append(tokens[0, 0, :-1:2])\n",
    "    query_int_reprs.append(tokens[:, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_repr(context_data, queries, agent_path, task_i):\n",
    "    print(task_i)\n",
    "    llm_params, llm_model, _ = load_llm(agent_path)\n",
    "\n",
    "    context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "    context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]\n",
    "\n",
    "    print(context_inputs, context_outputs)\n",
    "\n",
    "    if queries is None:\n",
    "        queries = context_inputs\n",
    "        print(\"USE CONTEXT INPUTS\")\n",
    "    else:\n",
    "        print(\"USE QUERIES\")\n",
    "\n",
    "    repr, _ = jax.vmap(llm_model.get_latent, in_axes=[None, 0, None])(\n",
    "        llm_params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "        queries[:, None, None],\n",
    "        {\n",
    "            CONST_CONTEXT_INPUT: context_inputs[None],\n",
    "            CONST_CONTEXT_OUTPUT: context_outputs[None],\n",
    "        },\n",
    "    )\n",
    "    print(repr)\n",
    "\n",
    "    return repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_og_res = get_agent_repr(context_data, None, agent_path, task_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(tokens[:, 0, -1] - query_og_res[:, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(query_int_reprs[-1] - query_og_res[:, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(agent_reprs[agent_path][\"query_context_reprs\"][task_i] - query_int_reprs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(agent_reprs[agent_path][\"query_context_reprs\"][task_i] - query_og_res[:, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_path = list(agent_reprs.keys())[0]\n",
    "print(agent_path)\n",
    "\n",
    "for input_repr in input_int_reprs:\n",
    "    print(np.allclose(agent_reprs[agent_path][\"input_context_reprs\"][task_i], input_repr))\n",
    "\n",
    "print(\n",
    "    np.max((agent_reprs[agent_path][\"input_context_reprs\"][task_i] - input_repr)),\n",
    "    np.min((agent_reprs[agent_path][\"input_context_reprs\"][task_i] - input_repr))\n",
    ")\n",
    "\n",
    "for query_repr in query_int_reprs:\n",
    "    print(np.allclose(agent_reprs[agent_path][\"query_context_reprs\"][task_i], query_repr))\n",
    "\n",
    "print(\n",
    "    np.max((agent_reprs[agent_path][\"query_context_reprs\"][task_i] - query_repr)),\n",
    "    np.min((agent_reprs[agent_path][\"query_context_reprs\"][task_i] - query_repr))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.models.svm import *\n",
    "\n",
    "svm_input_reprs = []\n",
    "svm_query_reprs = []\n",
    "train_y = np.argmax(context_outputs, axis=-1)\n",
    "train_y[train_y == 0] = -1\n",
    "for input_int_repr, query_int_repr in zip(input_int_reprs, query_int_reprs):\n",
    "    print(input_int_repr.shape, query_int_repr.shape)\n",
    "    svm_input_reprs.append(\n",
    "        primal_svm(input_int_repr, train_y)\n",
    "    )\n",
    "    svm_query_reprs.append(\n",
    "        primal_svm(query_int_repr, train_y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = math.ceil(len(svm_query_reprs) / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "for ax_i, (svm_repr, context_repr, context_input_repr) in enumerate(zip(svm_query_reprs, query_int_reprs, context_input_reprs)):\n",
    "    ax = axes[ax_i // ncols, ax_i % ncols]\n",
    "\n",
    "    svm_primal = svm_repr[1]\n",
    "    svm_preds = (\n",
    "        (\n",
    "            np.array(context_input_repr) @ svm_primal[:-1]\n",
    "            + svm_primal[-1:]\n",
    "        )\n",
    "        >= 0\n",
    "    ).astype(int)\n",
    "    \n",
    "    for possible_label in [0, 1]:\n",
    "        idxes = np.where(svm_preds == possible_label)\n",
    "        ax.scatter(\n",
    "            gt[\"inputs\"][idxes][:, 0],\n",
    "            gt[\"inputs\"][idxes][:, 1],\n",
    "            label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "            s=5,\n",
    "            alpha=0.1\n",
    "        )\n",
    "    for possible_label in [-1, 1]:\n",
    "        idxes = np.where(train_y == possible_label)\n",
    "        ax.scatter(\n",
    "            context_inputs[idxes][:, 0],\n",
    "            context_inputs[idxes][:, 1],\n",
    "            label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "            s=15,\n",
    "            marker=\"x\" if possible_label == 1 else \"o\",\n",
    "            c=\"black\"\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "    ax.set_ylim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "    ax.set_title(\"repr {}\".format(ax_i))\n",
    "    ax.grid(False)\n",
    "\n",
    "fig.legend(\n",
    "    bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=4,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    fontsize=\"8\",\n",
    ")\n",
    "fig.suptitle(\"Context-input Query Intermediate Representation\")\n",
    "fig.supxlabel(\"$x_1$\")\n",
    "fig.supylabel(\"$x_2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = math.ceil(len(svm_input_reprs) / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "for ax_i, (svm_repr, context_repr, context_input_repr) in enumerate(zip(svm_input_reprs, input_int_reprs, context_input_reprs)):\n",
    "    ax = axes[ax_i // ncols, ax_i % ncols]\n",
    "\n",
    "    svm_primal = svm_repr[1]\n",
    "    svm_preds = (\n",
    "        (\n",
    "            np.array(context_input_repr) @ svm_primal[:-1]\n",
    "            + svm_primal[-1:]\n",
    "        )\n",
    "        >= 0\n",
    "    ).astype(int)\n",
    "    \n",
    "    for possible_label in [0, 1]:\n",
    "        idxes = np.where(svm_preds == possible_label)\n",
    "        ax.scatter(\n",
    "            gt[\"inputs\"][idxes][:, 0],\n",
    "            gt[\"inputs\"][idxes][:, 1],\n",
    "            label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "            s=5,\n",
    "            alpha=0.1\n",
    "        )\n",
    "    for possible_label in [-1, 1]:\n",
    "        idxes = np.where(train_y == possible_label)\n",
    "        ax.scatter(\n",
    "            context_inputs[idxes][:, 0],\n",
    "            context_inputs[idxes][:, 1],\n",
    "            label=f\"{possible_label}\" if ax_i == 0 else \"\",\n",
    "            s=15,\n",
    "            marker=\"x\" if possible_label else \"o\",\n",
    "            c=\"black\"\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "    ax.set_ylim(input_range[0] - 0.01, input_range[1] + 0.01)\n",
    "    ax.set_title(\"repr {}\".format(ax_i))\n",
    "    ax.grid(False)\n",
    "\n",
    "fig.legend(\n",
    "    bbox_to_anchor=(0.0, 1.0, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=4,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    fontsize=\"8\",\n",
    ")\n",
    "fig.supxlabel(\"$x_1$\")\n",
    "fig.supylabel(\"$x_2$\")\n",
    "fig.suptitle(\"Context-input Input Intermediate Representation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Write my own self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpt_block_key, gpt_block_params in agent_model[0][CONST_MODEL_DICT][CONST_MODEL][\"gpt\"][\"params\"].items():\n",
    "    print(gpt_block_params.get(\"SelfAttention_0\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "def recover_dual_from_primal(primal_sol, train_x, train_y):\n",
    "    assert len(train_x.shape) == 2\n",
    "    assert len(train_y.shape) == 1\n",
    "\n",
    "    N, _ = train_x.shape\n",
    "\n",
    "    print(\"Primal solution: {}, shape: {}\".format(primal_sol, primal_sol.shape))\n",
    "\n",
    "    primal_out = (train_x @ primal_sol[:-1]) + primal_sol[-1]\n",
    "    primal_constraints = 2 * (0.5 - (1 - train_y)) * primal_out\n",
    "    coefs = 1 - primal_constraints\n",
    "    coefs[np.isclose(coefs, 0)] = 0\n",
    "    G = np.eye(N)\n",
    "    h = np.zeros(N)\n",
    "    dual_var = cp.Variable(N)\n",
    "    prob = cp.Problem(\n",
    "        cp.Maximize(coefs.T @ dual_var),\n",
    "        [G @ dual_var >= h],\n",
    "    )\n",
    "    loss = 0.5 * (np.linalg.norm(primal_sol[:-1]) ** 2) + prob.solve(verbose=False)\n",
    "    alphas = dual_var.value\n",
    "    return loss, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for task_i in context_data:\n",
    "    context_inputs = context_data[task_i][CONST_CONTEXT_INPUT]\n",
    "    context_outputs = context_data[task_i][CONST_CONTEXT_OUTPUT]\n",
    "    train_y = np.argmax(context_outputs, axis=-1)\n",
    "\n",
    "    for agent_path, agent_repr in agent_reprs.items():\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Processing agent {}\".format(agent_path))\n",
    "        print(\"-\" * 50)\n",
    "        print(\"input \")\n",
    "        print(\"-\" * 50)\n",
    "        # pprint(agent_repr[\"svms\"][task_i][\"input\"][\"dual\"])\n",
    "        loss, alphas = recover_dual_from_primal(\n",
    "            agent_repr[\"svms\"][task_i][\"input\"][\"primal\"][\"sol\"],\n",
    "            context_inputs,\n",
    "            train_y\n",
    "        )\n",
    "        # pprint({\n",
    "        #     \"loss\": loss,\n",
    "        #     \"sol\": alphas,\n",
    "        # })\n",
    "        # print(np.argsort(agent_repr[\"svms\"][task_i][\"input\"][\"dual\"][\"sol\"]))\n",
    "        sort_idxes = np.argsort(alphas)\n",
    "        print(\"Primal loss: {}, Dual loss: {}\".format(\n",
    "            agent_repr[\"svms\"][task_i][\"input\"][\"primal\"][\"loss\"],\n",
    "            loss\n",
    "        ))\n",
    "        print(\"Dual solution (sorted): {}\".format(alphas[sort_idxes]))\n",
    "        print(\"Sort indices: {}\".format(sort_idxes))\n",
    "        for repr_key in [\"query_context_reprs\", \"input_context_reprs\"]:\n",
    "            print(\"-\" * 50)\n",
    "            print(repr_key)\n",
    "            print(\"-\" * 50)\n",
    "            # pprint(agent_repr[\"svms\"][task_i][repr_key][\"dual\"])\n",
    "            loss, alphas = recover_dual_from_primal(\n",
    "                np.array(agent_repr[\"svms\"][task_i][repr_key][\"primal\"][\"sol\"]),\n",
    "                np.array(agent_repr[repr_key][task_i]),\n",
    "                train_y\n",
    "            )\n",
    "            # pprint({\n",
    "            #     \"loss\": loss,\n",
    "            #     \"sol\": alphas,\n",
    "            # })\n",
    "            # print(np.argsort(agent_repr[\"svms\"][task_i][repr_key][\"dual\"][\"sol\"]))\n",
    "            sort_idxes = np.argsort(alphas)\n",
    "            print(\"Primal loss: {}, Dual loss: {}\".format(\n",
    "                agent_repr[\"svms\"][task_i][repr_key][\"primal\"][\"loss\"],\n",
    "                loss\n",
    "            ))\n",
    "            print(\"Dual solution (sorted): {}\".format(alphas[sort_idxes]))\n",
    "            print(\"Sort indices: {}\".format(sort_idxes))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
