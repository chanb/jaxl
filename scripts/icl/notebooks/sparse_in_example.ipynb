{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets import get_dataset\n",
    "from jaxl.learning_utils import get_learner\n",
    "from jaxl.utils import parse_dict\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import optax\n",
    "import os\n",
    "\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/chanb/research/personal/jaxl/jaxl\"\n",
    "learner_path = \"/Users/chanb/research/personal/jaxl/jaxl/logs/icl-noiseless-no_bias-2d_linear-active_dim_2-full_context_16/gpt-pos_enc-09-09-23_15_09_55-0c965292-9e2e-4268-87df-3221b558bb19\"\n",
    "test_dataset_seed = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(learner_path, \"config.json\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "    config = parse_dict(config_dict)\n",
    "    \n",
    "learner = get_learner(\n",
    "    config.learner_config, config.model_config, config.optimizer_config\n",
    ")\n",
    "\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    os.path.join(learner_path, \"models\"),\n",
    "    PyTreeCheckpointer(),\n",
    ")\n",
    "\n",
    "params = checkpoint_manager.restore(checkpoint_manager.latest_step())\n",
    "params[CONST_MODEL_DICT][CONST_MODEL][CONST_POSITIONAL_ENCODING] = dict()\n",
    "model = learner._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.learner_config.dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 80\n",
    "input_range = [-1.0, 1.0]\n",
    "test_config = vars(config.learner_config.dataset_config)\n",
    "test_config[\"dataset_kwargs\"] = vars(test_config[\"dataset_kwargs\"])\n",
    "test_config[\"dataset_kwargs\"][\"sequence_length\"] = sequence_len + 1\n",
    "test_config[\"dataset_kwargs\"][\"params_bound\"] = [-0.5, 0.5]\n",
    "test_config[\"dataset_kwargs\"][\"inputs_range\"] = input_range\n",
    "ns_test_config = parse_dict(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset(ns_test_config, seed=test_dataset_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(dataset, sequence_length):\n",
    "    context_inputs, context_outputs, queries, outputs = [], [], [], []\n",
    "    for seq_i in range(sequence_length):\n",
    "        context_input, context_output, query, output = dataset[seq_i]\n",
    "        context_inputs.append(context_input)\n",
    "        context_outputs.append(context_output)\n",
    "        queries.append(query)\n",
    "        outputs.append(output)\n",
    "    context_inputs = np.stack(context_inputs)\n",
    "    context_outputs = np.stack(context_outputs)\n",
    "    queries = np.stack(queries)\n",
    "    outputs = np.stack(outputs)\n",
    "\n",
    "    preds, _ = model.forward(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "        queries,\n",
    "        {\n",
    "            CONST_CONTEXT_INPUT: context_inputs,\n",
    "            CONST_CONTEXT_OUTPUT: context_outputs,\n",
    "        }\n",
    "    )\n",
    "    return queries, preds, outputs, context_inputs, context_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(logits, y_one_hot):\n",
    "    return np.mean(optax.softmax_cross_entropy(logits, y_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, preds, outputs, context_inputs, context_outputs = get_result(\n",
    "    test_dataset,\n",
    "    sequence_length=sequence_len\n",
    ")\n",
    "loss = ce_loss(preds, outputs)\n",
    "print(queries.shape, preds.shape, outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_len = config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len\n",
    "pred_labels = np.argmax(preds[context_len:], axis=-1)\n",
    "for possible_label in [0, 1]:\n",
    "    idxes = np.where(pred_labels == possible_label)\n",
    "    plt.scatter(queries[context_len:, 0, 0][idxes], queries[context_len:, 0, 1][idxes], label=f\"{possible_label}\")\n",
    "\n",
    "decision_boundary = test_dataset.params[0]\n",
    "\n",
    "out = -np.array(input_range) * decision_boundary[1] / decision_boundary[2]\n",
    "plt.plot(np.array(input_range), out, label=\"decision boundary\", color=\"black\")\n",
    "\n",
    "plt.xlim(input_range[0], input_range[1])\n",
    "plt.ylim(input_range[0], input_range[1])\n",
    "plt.legend(\n",
    "    bbox_to_anchor=(0.0, 1.01, 1.0, 0.0),\n",
    "    loc=\"lower center\",\n",
    "    ncols=3,\n",
    "    borderaxespad=0.0,\n",
    "    frameon=True,\n",
    "    # fontsize=\"8\",\n",
    ")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVC(\n",
    "        dual=\"auto\",\n",
    "        loss=\"hinge\",\n",
    "        random_state=0,\n",
    "        tol=1e-7,\n",
    "        C=10.0,\n",
    "    )\n",
    ")\n",
    "svm.fit(context_inputs[-1], np.argmax(context_outputs[-1], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = svm.decision_function(context_inputs[-1])\n",
    "print(decision_function)\n",
    "support_vector_indices = np.where(np.abs(decision_function) <= 1)[0]\n",
    "support_vectors = context_inputs[-1][support_vector_indices]\n",
    "\n",
    "plt.scatter(context_inputs[-1][:, 0], context_inputs[-1][:, 1], c=context_outputs[-1, ..., -1], s=30, cmap=plt.cm.Paired)\n",
    "ax = plt.gca()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    svm,\n",
    "    context_inputs[-1],\n",
    "    ax=ax,\n",
    "    grid_resolution=50,\n",
    "    plot_method=\"contour\",\n",
    "    colors=\"k\",\n",
    "    levels=[-1, 0, 1],\n",
    "    alpha=0.5,\n",
    "    linestyles=[\"--\", \"-\", \"--\"],\n",
    ")\n",
    "plt.scatter(\n",
    "    support_vectors[:, 0],\n",
    "    support_vectors[:, 1],\n",
    "    s=100,\n",
    "    linewidth=1,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"k\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
