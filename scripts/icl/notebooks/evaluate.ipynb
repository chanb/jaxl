{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets import get_dataset\n",
    "from jaxl.learning_utils import get_learner\n",
    "from jaxl.utils import parse_dict\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/chanb/research/personal/jaxl/jaxl\"\n",
    "# learner_path = os.path.join(\n",
    "#     base_dir,\n",
    "#     \"logs/icl-linear_sgd-full_context_20/gpt-no_enc-08-21-23_07_36_59-971a17db-73ed-4f77-b463-5887644e3385\"\n",
    "# )\n",
    "learner_path = os.path.join(\n",
    "    base_dir,\n",
    "    \"logs/icl-linear_sgd-full_context_20/gpt-pos_enc-08-21-23_07_36_58-5473978c-10db-433b-889b-f136405d7a7e\"\n",
    ")\n",
    "test_dataset_seed = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(learner_path, \"config.json\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "    config = parse_dict(config_dict)\n",
    "    \n",
    "learner = get_learner(\n",
    "    config.learner_config, config.model_config, config.optimizer_config\n",
    ")\n",
    "\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    os.path.join(learner_path, \"models\"),\n",
    "    PyTreeCheckpointer(),\n",
    ")\n",
    "\n",
    "params = checkpoint_manager.restore(checkpoint_manager.latest_step())\n",
    "params[CONST_MODEL_DICT][CONST_MODEL][CONST_POSITIONAL_ENCODING] = dict()\n",
    "model = learner._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.learner_config.dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 80\n",
    "test_config = vars(config.learner_config.dataset_config)\n",
    "test_config[\"dataset_kwargs\"] = vars(test_config[\"dataset_kwargs\"])\n",
    "test_config[\"dataset_kwargs\"][\"sequence_length\"] = sequence_len + 1\n",
    "test_config[\"dataset_kwargs\"][\"params_bound\"] = [-0.5, 0.5]\n",
    "test_config[\"dataset_kwargs\"][\"inputs_range\"] = [-0.5, 0.5]\n",
    "test_config = parse_dict(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset(test_config, seed=test_dataset_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(dataset, sequence_length):\n",
    "    context_inputs, context_outputs, queries, outputs = [], [], [], []\n",
    "    for seq_i in range(sequence_length):\n",
    "        context_input, context_output, query, output = dataset[seq_i]\n",
    "        context_inputs.append(context_input)\n",
    "        context_outputs.append(context_output)\n",
    "        queries.append(query)\n",
    "        outputs.append(output)\n",
    "    context_inputs = np.stack(context_inputs)\n",
    "    context_outputs = np.stack(context_outputs)\n",
    "    queries = np.stack(queries)\n",
    "    outputs = np.stack(outputs)\n",
    "\n",
    "    preds, _ = model.forward(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "        queries,\n",
    "        {\n",
    "            CONST_CONTEXT_INPUT: context_inputs,\n",
    "            CONST_CONTEXT_OUTPUT: context_outputs,\n",
    "        }\n",
    "    )\n",
    "    return queries, preds, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, outputs):\n",
    "    return np.mean((preds - outputs) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, preds, outputs = get_result(\n",
    "    test_dataset,\n",
    "    sequence_length=sequence_len\n",
    ")\n",
    "loss = mse(preds, outputs)\n",
    "print(queries.shape, preds.shape, outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_len = config.learner_config.dataset_config.dataset_wrapper.kwargs.context_len\n",
    "plt.scatter(queries[context_len:], preds[context_len:], label=\"prediction\")\n",
    "plt.scatter(queries[context_len:], outputs[context_len:], label=\"ground truth\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(dataset, sequence_length):\n",
    "    context_inputs, context_outputs, queries, outputs = [], [], [], []\n",
    "    for seq_i in range(sequence_length):\n",
    "        context_input, context_output, query, output = dataset[seq_i]\n",
    "        context_inputs.append(context_input)\n",
    "        context_outputs.append(context_output)\n",
    "        queries.append(query)\n",
    "        outputs.append(output)\n",
    "    context_inputs = np.stack(context_inputs)\n",
    "    context_outputs = np.stack(context_outputs)\n",
    "    queries = np.stack(queries)\n",
    "    outputs = np.stack(outputs)\n",
    "\n",
    "    latent, _ = model.get_latent(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "        queries,\n",
    "        {\n",
    "            CONST_CONTEXT_INPUT: context_inputs,\n",
    "            CONST_CONTEXT_OUTPUT: context_outputs,\n",
    "        }\n",
    "    )\n",
    "    return queries, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, latents = get_latent(\n",
    "    test_dataset,\n",
    "    sequence_length=sequence_len\n",
    ")\n",
    "print(queries.shape, latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.utils import l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent in latents:\n",
    "    print(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
