{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Attention Layers on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxl.constants import *\n",
    "from jaxl.datasets import get_dataset\n",
    "from jaxl.datasets.wrappers import (\n",
    "    ContextDataset,\n",
    "    StandardSupervisedDataset,\n",
    "    FixedLengthContextDataset,\n",
    "    RepeatedContextDataset,\n",
    ")\n",
    "from jaxl.models import load_config, load_model, get_model, get_activation\n",
    "from jaxl.models.modules import GPTModule\n",
    "from jaxl.plot_utils import set_size\n",
    "from jaxl.utils import parse_dict, get_device\n",
    "\n",
    "import _pickle as pickle\n",
    "import copy\n",
    "import jax\n",
    "import jax.random as jrandom\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import torchvision.datasets as torch_datasets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from orbax.checkpoint import PyTreeCheckpointer, CheckpointManager\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"gpu:0\"\n",
    "get_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_width_pt = 750.0\n",
    "\n",
    "base_path = \"/home/bryanpu1/projects/icl/jaxl/\"\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "log_path = os.path.join(base_path, \"jaxl/logs\")\n",
    "project_name = \"icl-mnist\"\n",
    "ablation_name = \"include_query_class-random_label\"\n",
    "run_name = (\n",
    "    # \"default-03-17-24_13_01_35-af1cc36f-8698-4a61-a16a-4d2c726a22b9\"\n",
    "    # \"variable_len-03-18-24_10_21_12-2ac5a55c-b1cf-448b-945b-e6b8f821431f\"\n",
    "    \"variable_len-include_query_class-03-18-24_10_21_18-31a5371d-c10d-4595-a26e-1b0158a4b0d4\"\n",
    ")\n",
    "\n",
    "learner_path = os.path.join(\n",
    "    log_path,\n",
    "    project_name,\n",
    "    ablation_name,\n",
    "    run_name,\n",
    ")\n",
    "\n",
    "exp_name = \"-\".join(run_name.split(\"-\")[:-8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict, config = load_config(learner_path)\n",
    "fixed_length = config.learner_config.dataset_config.dataset_wrapper.type in [\"FixedLengthContextDataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(\n",
    "    config.learner_config.dataset_config,\n",
    "    config.learner_config.seeds.data_seed,\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    sampler=SequentialSampler(train_dataset),\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, model = load_model(\n",
    "    train_dataset.input_dim, train_dataset.output_dim, learner_path, -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tasks = 1\n",
    "max_label = CONST_AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModule(\n",
    "    num_blocks=config.model_config.num_blocks,\n",
    "    num_heads=config.model_config.num_heads,\n",
    "    embed_dim=config.model_config.embed_dim,\n",
    "    widening_factor=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[CONST_MODEL_DICT][CONST_MODEL].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "num_query_class_in_context = []\n",
    "\n",
    "for batch_i, samples in enumerate(data_loader):\n",
    "    if batch_i >= num_tasks:\n",
    "        break\n",
    "\n",
    "    (context_inputs, context_outputs, queries, one_hot_labels) = samples\n",
    "\n",
    "    in_tokens, _, _ = model.tokenize(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL],\n",
    "        queries.numpy(),\n",
    "        {\n",
    "            CONST_CONTEXT_INPUT: context_inputs.numpy(),\n",
    "            CONST_CONTEXT_OUTPUT: context_outputs.numpy(),\n",
    "        },\n",
    "        eval=True,\n",
    "    )\n",
    "\n",
    "    out_tokens, latents = gpt.apply(\n",
    "        params[CONST_MODEL_DICT][CONST_MODEL][CONST_GPT],\n",
    "        in_tokens,\n",
    "        eval=True,\n",
    "        capture_intermediates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latents[\"intermediates\"][\"GPTBlock_{}\".format(block_i)].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [in_tokens]\n",
    "for block_i in range(config.model_config.num_blocks):\n",
    "    all_tokens.append(latents[\"intermediates\"][\"GPTBlock_{}\".format(block_i)][\"SelfAttention_0\"][\"out\"][\"__call__\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 4\n",
    "for example_i in range(num_examples):\n",
    "    ci, co, q, l = train_dataset[\n",
    "        example_i\n",
    "    ]\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = 8\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows,\n",
    "        ncols + 1,\n",
    "        figsize=set_size(doc_width_pt, 0.95, (nrows, ncols), False),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for idx, (img, label) in enumerate(zip(ci, co)):\n",
    "        axes[idx // ncols, idx % ncols].imshow(img)\n",
    "        axes[idx // ncols, idx % ncols].set_title(np.argmax(label))\n",
    "        axes[idx // ncols, idx % ncols].axis('off')\n",
    "    axes[0, -1].axis('off')\n",
    "    axes[1, -1].axis('off')\n",
    "    axes[1, -1].imshow(q[0])\n",
    "    axes[1, -1].set_title(np.argmax(l, axis=-1))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(a, b):\n",
    "    return a @ b.T\n",
    "\n",
    "dist = jax.vmap(cosine_distance)\n",
    "\n",
    "for plot_i, (in_tokens, out_tokens) in enumerate(zip(all_tokens[:-1], all_tokens[1:])):\n",
    "    for sample in dist(in_tokens, out_tokens):\n",
    "        print(sample[-1])\n",
    "        ax = sns.heatmap(sample, linewidth=0.5)\n",
    "        plt.title(\"Layer {}\".format(plot_i))\n",
    "        plt.xlabel(\"output tokens\")\n",
    "        plt.ylabel(\"input tokens\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
