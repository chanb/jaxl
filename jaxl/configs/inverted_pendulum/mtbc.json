{
    "logging_config": {
        "save_path": "./logs/inverted_pendulum",
        "experiment_name": "mtbc",
        "log_interval": 1,
        "checkpoint_interval": 500
    },
    "model_config": {
        "architecture": "encoder_predictor",
        "predictor": {
            "architecture": "ensemble",
            "model": {
                "architecture": "mlp",
                "layers": []
            },
            "num_models": 2,
            "input_dim": 128
        },
        "encoder": {
            "architecture": "mlp",
            "layers": [128]
        },
        "encoder_dim": [128],
        "encoder_name": "representation",
        "predictor_name": "policy"
    },
    "optimizer_config": {
        "policy": {
            "optimizer": "adam",
            "lr": 3e-4,
            "max_grad_norm": 10.0
        },
        "representation": {
            "optimizer": "adam",
            "lr": 3e-4,
            "max_grad_norm": 10.0
        }
    },
    "learner_config": {
        "task": "imitation_learning",
        "buffer_configs": [
            {
                "load_buffer": "/Users/chanb/research/personal/jaxl/data/inverted_pendulum/10_episodes-env_seed_1.gzip",
                "buffer_type": "default"
            },
            {
                "load_buffer": "/Users/chanb/research/personal/jaxl/data/inverted_pendulum/10_episodes-env_seed_2.gzip",
                "buffer_type": "default"
            }
        ],
        "seeds": {
            "model_seed": 42,
            "buffer_seed": 42
        },
        "learner": "mtbc",
        "num_updates_per_epoch": 100,
        "batch_size": 64,
        "obs_rms": false,
        "losses": ["gaussian", "l2"],
        "loss_settings": [
            {
                "coefficient": 1.0,
                "reduction": "mean"
            },
            {
                "coefficient": 0.0002
            }
        ]
    },
    "train_config": {
        "num_epochs": 10000
    }
}