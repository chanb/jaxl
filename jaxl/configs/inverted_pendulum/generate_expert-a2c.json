{
    "logging_config": {
        "save_path": "./logs/inverted_pendulum",
        "experiment_name": "a2c",
        "log_interval": 1,
        "checkpoint_interval": 10
    },
    "model_config": {
        "policy": {
            "architecture": "mlp",
            "layers": [128, 128]
        },
        "vf": {
            "architecture": "mlp",
            "layers": [128, 128]
        }
    },
    "optimizer_config": {
        "policy": {
            "optimizer": "adam",
            "lr": 1e-3
        },
        "vf": {
            "optimizer": "adam",
            "lr": 1e-3
        }
    },
    "learner_config": {
        "task": "reinforcement_learning",
        "env_config": {
            "env_type": "gym",
            "env_name": "InvertedPendulum-v4",
            "env_kwargs": {}
        },
        "seeds": {
            "model_seed": 42,
            "buffer_seed": 42,
            "env_seed": 42
        },
        "buffer_config": {
            "buffer_type": "default",
            "buffer_size": 2048
        },
        "learner": "a2c",
        "gamma": 0.99,
        "obs_rms": true,
        "value_rms": true,
        "policy_distribution": "gaussian",
        "min_std": 1e-7,
        "vf_loss_setting": {
            "coefficient": 1.0,
            "reduction": "mean"
        },
        "pi_loss_setting": {
            "coefficient": 1.0,
            "reduction": "mean"
        }
    },
    "train_config": {
        "num_epochs": 1000
    }
}
