{
    "logging_config": {
        "save_path": "./logs/dmc/cheetah/objective_comparison",
        "experiment_name": "reverse_kl-tanh",
        "log_interval": 1,
        "checkpoint_interval": 25
    },
    "model_config": {
        "policy": {
            "architecture": "mlp",
            "layers": [64, 64],
            "activation": "tanh"
        },
        "vf": {
            "architecture": "mlp",
            "layers": [64, 64],
            "activation": "tanh"
        }
    },
    "optimizer_config": {
        "policy": {
            "optimizer": "adam",
            "lr": {
                "scheduler": "constant_schedule",
                "scheduler_kwargs": {
                    "value": 3e-4
                }
            },
            "max_grad_norm": false
        },
        "vf": {
            "optimizer": "adam",
            "lr": {
                "scheduler": "constant_schedule",
                "scheduler_kwargs": {
                    "value": 3e-4
                }
            },
            "max_grad_norm": false
        }
    },
    "learner_config": {
        "task": "reinforcement_learning",
        "env_config": {
            "env_type": "gym",
            "env_name": "DMCCheetah-v0",
            "env_kwargs": {
                "seed": 0,
                "use_default": true,
                "control_mode": "discrete"
            }
        },
        "seeds": {
            "model_seed": 43,
            "buffer_seed": 43,
            "env_seed": 43
        },
        "buffer_config": {
            "buffer_type": "default",
            "buffer_size": 2048
        },
        "num_steps_per_epoch": 2048,
        "learner": "ppo",
        "gamma": 0.99,
        "gae_lambda": 0.95,
        "normalize_advantage": true,
        "eps": 1e-5,
        "obs_rms": true,
        "value_rms": false,
        "policy_distribution": "softmax",
        "temperature": 1.0,
        "opt_batch_size": 256,
        "opt_epochs": 100,
        "kl_threshold": false,
        "update_before_early_stopping": false,
        "ent_loss_setting": {
            "scheduler": "constant_schedule",
            "scheduler_kwargs": {
                "value": 0
            }
        },
        "vf_loss_setting": {
            "coefficient": 0.5,
            "reduction": "mean",
            "clip_param": false
        },
        "pi_loss_setting": {
            "objective": "reverse_kl",
            "coefficient": 1.0,
            "reduction": "mean",
            "clip_param": 0.2,
            "beta": 0.02
        }
    },
    "train_config": {
        "num_epochs": 1000
    }
}
